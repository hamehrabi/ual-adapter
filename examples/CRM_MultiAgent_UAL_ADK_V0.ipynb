{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸš€ Multi-Agent CRM System with UAL Adapter + Google ADK\n",
        "\n",
        "**Simple Demonstration of Universal LoRA Transfer for Multi-Agent Systems**\n",
        "\n",
        "## What This Showcases\n",
        "\n",
        "âœ¨ **End-to-End CRM Automation** powered by specialized AI agents  \n",
        "âœ¨ **Train Once, Deploy Anywhere** via the **UAL Adapter** â€” universal LoRA transfer  \n",
        "## âœ¨ **Dynamic Skill Adoption** from an **AIR repository** (architecture-agnostic adapters)  \n",
        "âœ¨ **Intelligent Orchestration** with **Gemini Flash 2.5** as planner/router  \n",
        "âœ¨ **Scalable Real-World Use Case** â€” full CRM workflow handled by agents\n",
        "\n",
        "1. Creates tool functions that connect Google ADK to your backend models\n",
        "2. Builds 4 specialist agents (one for each role)\n",
        "3. Creates a Planner agent that orchestrates everything\n",
        "4. Establishes the complete multi-agent system\n",
        "\n",
        "### ğŸ—ï¸ **Architecture**\n",
        "\n",
        "```\n",
        "    Customer Query\n",
        "          â†“\n",
        "    [Gemini Planner]\n",
        "          â†“\n",
        "    Analyzes & Routes\n",
        "          â†“\n",
        "     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”\n",
        "     â†“         â†“    â†“    â†“\n",
        "  Sales   Support Acct Data\n",
        "   Rep     Spec   Mgr  Analyst\n",
        "   â†“         â†“      â†“    â†“\n",
        " Qwen   TinyLlama SmolLM Qwen\n",
        " 0.5B     1.1B    360M  1.5B\n",
        "   â†“         â†“      â†“    â†“\n",
        "Dispatcher Dispatcher Dispatcher\n",
        "   â†“         â†“      â†“    â†“\n",
        "Skills   Skills  Skills Skills\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **How It Works**\n",
        "\n",
        "1. Customer asks a question\n",
        "2. Planner analyzes and routes to best agent\n",
        "3. Agent calls its tool function\n",
        "4. Tool uses backend model + dispatcher\n",
        "5. Dispatcher selects best skill\n",
        "6. Result flows back to customer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-ABrsFwUS2L_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVg8ooY9It_Z"
      },
      "source": [
        "## ğŸ“¦ Installation & Setup\n",
        "This cell installs all the required Python packages needed to run the Multi-Agent CRM system. Think of it as setting up your workspace with all the tools you'll need.\n",
        "\n",
        "### ğŸ”§ **Packages Being Installed**\n",
        "\n",
        "#### Core UAL Framework:\n",
        "- **`ual-adapter`** - The star of the show! This is the Universal Adapter package you built that enables architecture-agnostic LoRA transfer\n",
        "- **`transformers`** - Hugging Face library for loading and using pre-trained language models\n",
        "- **`torch`** - PyTorch deep learning framework (the engine that runs the models)\n",
        "- **`accelerate`** - Makes model loading faster and handles GPU/CPU distribution\n",
        "- **`sentencepiece`** & **`protobuf`** - Required for tokenization (breaking text into model-readable pieces)\n",
        "\n",
        "#### Agent Orchestration & Visualization:\n",
        "- **`google-genai`** - Google's Gemini API client for the planner/router agent\n",
        "- **`matplotlib`** - For creating visualizations and charts\n",
        "- **`pandas`** - Data manipulation and analysis\n",
        "- **`rich`** - Beautiful terminal output and formatting\n",
        "\n",
        "### âš™ï¸ **Installation Flags Explained**\n",
        "- **`-q`** (quiet mode) - Hides verbose installation output, shows only essential information\n",
        "- **`!pip install`** - The `!` tells Colab to run this as a shell command, not Python code\n",
        "\n",
        "### â±ï¸ **Expected Time**\n",
        "This installation typically takes **1-2 minutes** depending on your connection speed.\n",
        "\n",
        "### âœ… **Success Indicator**\n",
        "When complete, you'll see: `âœ… Installation complete!`\n",
        "\n",
        "### ğŸ’¡ **Pro Tip**\n",
        "If you encounter any errors during installation, try:\n",
        "1. Restarting the runtime: `Runtime â†’ Restart runtime`\n",
        "2. Running the cell again\n",
        "3. Checking your internet connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGssDjhfIt_a",
        "outputId": "1b1ab987-1d1a-4e45-81ad-e04fbbf2ca90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Install all required packages\n",
        "!pip install -q ual-adapter transformers torch accelerate sentencepiece protobuf\n",
        "!pip install -q google-genai matplotlib pandas rich\n",
        "\n",
        "print('âœ… Installation complete!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLzbjpPHIt_e",
        "outputId": "adbed3b0-421e-4056-aa4f-cbe4ae8565d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… UAL Adapter: 0.1.0\n",
            "âœ… PyTorch: 2.8.0+cu126\n",
            "âœ… Device: GPU (NVIDIA A100-SXM4-40GB)\n"
          ]
        }
      ],
      "source": [
        "# Verify installation\n",
        "import torch\n",
        "import ual_adapter\n",
        "from ual_adapter import UniversalAdapter, LoRADispatcher\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f'âœ… UAL Adapter: {ual_adapter.__version__}')\n",
        "print(f'âœ… PyTorch: {torch.__version__}')\n",
        "print(f\"âœ… Device: {'GPU (' + torch.cuda.get_device_name(0) + ')' if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('\\nâš ï¸  WARNING: No GPU detected!')\n",
        "    print('Enable GPU: Runtime â†’ Change runtime type â†’ T4 GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLrmzKmkIt_f"
      },
      "source": [
        "## ğŸ”‘ Google ADK Configuration\n",
        "\n",
        "### ğŸ¯ **What This Does**\n",
        "Connects Google's Gemini AI to act as your intelligent planner. Gemini will read customer queries and decide which agent should handle them.\n",
        "\n",
        "### ğŸ” **Get Your Free API Key** (30 seconds)\n",
        "1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)\n",
        "2. Click \"Create API Key\"\n",
        "3. Copy it\n",
        "\n",
        "### ğŸ”’ **Add Your Key to Colab**\n",
        "1. Click the **ğŸ”‘** icon on the left sidebar\n",
        "2. Click \"+ Add new secret\"\n",
        "3. Name: `GOOGLE_API_KEY`\n",
        "4. Paste your key\n",
        "5. Toggle on the switch to allow access\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import google.genai as genai\n",
        "\n",
        "# Get your API key from Colab Secrets\n",
        "GEMINI_API_KEY = \"AIzasasedqweqw................._BgjEag\"  # Replace with your key\n",
        "\n",
        "# Set it up\n",
        "os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
        "\n",
        "print(\"âœ… Gemini connected and ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYQYtVw9p79K",
        "outputId": "33dba2be-7f70-44b3-af33-ebde6ed5c074"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini connected and ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ’¡ Defining Your CRM Skills - The Knowledge Foundation\n",
        "\n",
        "This cell creates the **knowledge base** that will train your specialized adapters. Think of these as \"expert training manuals\" - each contains deep, technical knowledge that general AI models don't have.\n",
        "\n",
        "### ğŸ§  **Why This Matters**\n",
        "Regular language models are generalists. These skill datasets transform them into CRM specialists with:\n",
        "- Real-world scenarios and solutions\n",
        "- Technical depth (Salesforce, HubSpot)\n",
        "- Best practices from industry experts\n",
        "- Actionable frameworks for complex tasks\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š **The 6 CRM Skills**\n",
        "\n",
        "**1. CRM Software Mastery** ğŸ”§\n",
        "- Salesforce workflows and automation\n",
        "- HubSpot custom objects and APIs\n",
        "- Enterprise-scale implementations\n",
        "\n",
        "**2. Negotiation Techniques** ğŸ¤\n",
        "- MEDDPICC qualification framework\n",
        "- Challenger sales approach\n",
        "- Multi-stakeholder deal strategies\n",
        "\n",
        "**3. Product Knowledge** ğŸ“¦\n",
        "- SaaS architecture and pricing\n",
        "- Security and compliance features\n",
        "- Competitive positioning\n",
        "\n",
        "**4. Data Analytics** ğŸ“Š\n",
        "- Churn prediction models\n",
        "- Customer segmentation\n",
        "- Pipeline analytics\n",
        "\n",
        "**5. Communication Protocols** ğŸ’¬\n",
        "- Email sequences\n",
        "- Discovery call frameworks\n",
        "- Objection handling scripts\n",
        "\n",
        "**6. Regulatory Compliance** âš–ï¸\n",
        "- GDPR compliance\n",
        "- CAN-SPAM regulations\n",
        "- SOC 2 audit processes\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ **Dataset Structure**\n",
        "Each skill contains **5 detailed examples**:\n",
        "- **300-500 words** per example\n",
        "- **Production-level** knowledge\n",
        "- **Specific tools** and workflows\n",
        "\n",
        "### ğŸ“ **The UAL Magic**\n",
        "Once trained, these adapters are:\n",
        "1. **Portable** - Work across different model architectures\n",
        "2. **Specialized** - Expert knowledge in each domain\n",
        "3. **On-demand** - Agents load skills as needed\n",
        "4. **Consistent** - Same quality across all model sizes\n",
        "\n"
      ],
      "metadata": {
        "id": "Tru369Oxq6P1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcyQOfbjOKTD",
        "outputId": "37fb9863-fb8c-438e-bea2-2bda8fe03808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 6 skills = comprehensive training datasets\n",
            "   Each example: 300-500 words of technical depth\n"
          ]
        }
      ],
      "source": [
        "# Expanded skill dataset\n",
        "crm_mastery_skill = [\n",
        "    \"\"\"Title: Record-Triggered Flows for High-Velocity Deals with Segmented Approvals\n",
        "\n",
        "Context: A global B2B SaaS organization uses Salesforce to manage 15k open opportunities per quarter. Sales Operations needs a no-code/lowâ€‘code automation that 1) standardizes field updates, 2) routes approvals based on deal size, 3) enforces legal review for specific industries, and 4) posts realâ€‘time status in Slack.\n",
        "\n",
        "Objective: Build a Recordâ€‘Triggered Flow (after save) on Opportunity to orchestrate approvals and operational updates, replacing legacy Process Builder automations.\n",
        "\n",
        "Design:\n",
        "1) Entry Criteria: AND(ISPICKVAL(StageName,\"Proposal/Price Quote\"), TEXT(Rating)=\"Hot\", AnnualRevenue__c > 1000000, NOT(ISBLANK(Amount))). Add a Decision node â€œDealTierâ€ with outcomes: Under_50k (Amount < 50000), Mid_50_500k (BETWEEN 50â€“500k), Over_500k (>500k).\n",
        "2) Field Updates: Compute Days_In_Stage__c = TODAY() â€“ Stage_Enter_Date__c. Set SLA_Target_Date__c = NOW() + CASE(DealTier, Under_50k, 1, Mid_50_500k, 2, Over_500k, 3, 2) business days. Use a subflow to normalize discount fields and lock negative margin deals.\n",
        "3) Approval Routing:\n",
        "   â€¢ Under $50k â†’ Manager_Approval_Queue\n",
        "   â€¢ $50â€“500k â†’ Regional_Director_Queue\n",
        "   â€¢ >$500k â†’ VP_Approval_Queue + parallel Legal_Review (Platform Event â€œLegalReviewRequested__eâ€ with payload {OppId, Industry, Discount}).\n",
        "4) Slack Notifications: Outbound message to Slack webhook with markdown summary and deep links. Post updates when Approval Status changes (use Platform Events or Change Data Capture to avoid recursion).\n",
        "5) Guardrails: Turn on â€œOptimize for Large Data Volumes,â€ set Flow Trigger Order < 50 to play nicely with MDM sync flows, and wrap DMLâ€‘heavy paths in Scheduled Paths to reduce transaction time.\n",
        "\n",
        "Validation & Observability: Create a custom object Flow_Audit__c to log Flow version, outcome path, actor, and execution time (ms). Build a Lightning Report + Dashboard for approval SLAs by tier. Add an Apex â€œFlowHealthCheckâ€ invocable action to surface governor issues to a Datadog events stream.\n",
        "\n",
        "Outcome: Median approval turnaround drops from 14h to 3.2h for subâ€‘$50k, and from 3 days to 22h for >$500k deals; legal throughput improves due to eventâ€‘driven parallelization. Change management is simplified because all paths are declarative and versioned under Flow Orchestrator governance.\"\"\",\n",
        "    \"\"\"Title: HubSpot Custom Objects for Partner Deals with Deep Workflow Branching\n",
        "\n",
        "Context: A channelâ€‘led motion requires modeling Partners, Partner Tiers, MDF Requests, and Coâ€‘Sell Opportunities beyond default HubSpot objects. Operations also needs complex routing and SLA controls for MDF approvals.\n",
        "\n",
        "Objective: Introduce two custom objects: â€œPartnerâ€ and â€œMDF_Requestâ€, relate them to Companies/Deals, and drive processes using Workflows with up to 20 if/then branches that evaluate object properties and relationships.\n",
        "\n",
        "Design:\n",
        "1) Data Model:\n",
        "   â€¢ Custom Object Partner: fields {partner_id, tier (Silver/Gold/Platinum), primary_region, specialization[], health_score}.\n",
        "   â€¢ Custom Object MDF_Request: fields {request_id, amount, activity_type, campaign_start/end, projected_pipeline, partner_id (assoc)}.\n",
        "   â€¢ Associations: Partner â†” Company (oneâ€‘toâ€‘many), Partner â†” Deal (manyâ€‘toâ€‘many), MDF_Request â†” Partner (manyâ€‘toâ€‘one).\n",
        "2) Enrollment Triggers: MDF_Request enters workflow when status = â€œSubmittedâ€ AND required fields present; additionally enroll when associated Partner.tier âˆˆ {Gold, Platinum} OR MDF.amount â‰¥ $10,000.\n",
        "3) Branching Logic:\n",
        "   â€¢ If (tier=Platinum AND region=EMEA) â†’ Autoâ€‘approve up to $5k with budget decrement; else if (tier=Gold AND activity_type in {Event, Webinar}) â†’ Route to Regional Marketing for review; else â†’ Global Programs.\n",
        "   â€¢ SLA timers: use â€œSet property value after delayâ€ for escalations; create a secondary branch to notify Partner Manager if SLA > 3 business days.\n",
        "4) Validation: Custom coded action (Node.js) checks for date overlaps and duplicate coâ€‘sell records via HubSpot API before approval. Failed validation writes an error note and reassigns to submitter.\n",
        "5) Analytics: Custom report â€œMDF ROIâ€ blends MDF_Request with influenced Deals to compute pipeline:spend and closedâ€‘won ratio by tier and activity.\n",
        "\n",
        "Outcome: MDF cycle time reduced 46%, influenced pipeline tracking becomes auditable, and Finance gets monthly rollâ€‘ups by tier/region with negligible manual intervention.\"\"\",\n",
        "    \"\"\"Title: Salesforce CRM Analytics (Einstein) with SAQL & Dataflows for Pipeline Hygiene\n",
        "\n",
        "Context: The CRO needs weekly visibility into stuck pipeline, stage aging, and discount leakage across three business units. The legacy dashboard uses static SOQL snapshots and hides stageâ€‘level nuances.\n",
        "\n",
        "Objective: Build a CRM Analytics app with dataflows that compute derived fields and SAQL lenses powering a â€œPipeline Hygieneâ€ dashboard with drillâ€‘downs.\n",
        "\n",
        "Dataflow:\n",
        "1) Extract Opportunity, OpportunityHistory, User, and Product tables via connectors.\n",
        "2) Compute fields:\n",
        "   â€¢ Days_In_Stage = datediff('day', StageEnteredDate, now())\n",
        "   â€¢ Price_to_List = Amount / (Quantity * ListPrice)\n",
        "   â€¢ Is_Backslid = case when lag(StageName) > StageName then true end\n",
        "   â€¢ Rolling_14d_Activity = window_sum(ActivityCount, 14d).\n",
        "3) Augment nodes: Join Opportunity with User (owner) and Product family; add Territory mapping.\n",
        "\n",
        "SAQL Highlights:\n",
        "â€¢ Build a lens â€œStage Aging Heatmapâ€ grouping by StageName, BU, and Days_In_Stage buckets (0â€‘7, 8â€‘14, 15â€‘30, 31â€‘60, 60+).\n",
        "â€¢ Lens â€œDiscount Leakageâ€ computes median discount by BU and owner quartile.\n",
        "â€¢ Lens â€œBackslide Radarâ€ flags opportunities with Is_Backslid=true in last 21 days.\n",
        "\n",
        "Dashboard UX:\n",
        "â€¢ KPI tiles for Pipeline Coverage (4Ã—), Stuck >30d, and Backslide Count.\n",
        "â€¢ Clickâ€‘through actions open a Lightning list view with preâ€‘applied filters.\n",
        "â€¢ Security predicates enforce BUâ€‘scoped visibility (rowâ€‘level security).\n",
        "\n",
        "Governance: Version dataflows in Git; schedule nightly refresh plus onâ€‘demand â€œhygiene pulseâ€ at 9am local per region. Add recipe tests to verify row counts and field drift.\n",
        "\n",
        "Outcome: Winâ€‘rate improves 3.1 points, average discount falls 1.7%, and managers proactively coach on stage aging because backslide trends are now visible and attributable.\"\"\",\n",
        "    \"\"\"Title: HubSpot API OAuth 2.0 Integration with Resilient Batch Upserts\n",
        "\n",
        "Context: Marketing needs to sync webinar registrants from a thirdâ€‘party platform into HubSpot Contacts and a custom object â€œWebinar_Attendance,â€ at scale (50k/day) with strict SLA and no duplicates.\n",
        "\n",
        "Objective: Implement an OAuth 2.0 authorization code flow, robust token refresh, and idempotent batch upserts using HubSpotâ€™s batch endpoints with backoff, retries, and deadâ€‘letter handling.\n",
        "\n",
        "Implementation:\n",
        "1) OAuth: Store client_id/secret in KMS. Use shortâ€‘lived access tokens (~6h) and longâ€‘lived refresh tokens. Build a refresh flow that proactively renews at Tâ€‘5 minutes; if refresh fails, alert via PagerDuty.\n",
        "2) Idempotency: Generate deterministic external ids like sha256(email|webinar_id). Use batch create/update endpoints in 100â€‘record pages. Maintain a â€œsync watermarkâ€ by event timestamp.\n",
        "3) Error Handling:\n",
        "   â€¢ 4xx validation errors â†’ write to DLQ (BigQuery table) with payload and reason, autoâ€‘open a JIRA ticket for schema drift.\n",
        "   â€¢ 429 / 5xx â†’ exponential backoff (jittered), retry up to 5 times, then DLQ.\n",
        "   â€¢ Partial failures â†’ retry only failed rows.\n",
        "4) Data Quality: Normalize emails, enforce ISO8601 timestamps, map UTM fields consistently, and validate country codes against ISOâ€‘3166.\n",
        "5) Observability: Emit metrics (ingested, updated, DLQ) and P95 latency to Prometheus; Grafana board shows hourly trends.\n",
        "\n",
        "Outcome: 99.98% success rate, nearâ€‘realâ€‘time enrichment for sales, and a clean audit trail that satisfies GDPR data lineage requirements.\"\"\",\n",
        "    \"\"\"Title: Eventâ€‘Driven Salesforce Integration with Platform Events and Circuit Breakers\n",
        "\n",
        "Context: The enterprise has brittle pointâ€‘toâ€‘point integrations causing API saturation and cascading failures during quarterly rush. We will decouple systems using an event backbone and protect downstreams with circuit breakers.\n",
        "\n",
        "Objective: Publish domain events from Salesforce (Platform Events), process them via middleware (e.g., Kafka or Pub/Sub), and implement resilience patterns in subscriber services and Apex.\n",
        "\n",
        "Architecture:\n",
        "1) Event Design: Define OpportunityUpdated__e and ContractSigned__e with minimal payload (ids + version + change mask). Keep the canonical record offâ€‘event; subscribers reâ€‘hydrate as needed.\n",
        "2) Publishing: Use afterâ€‘save triggers or flows to publish events only on materially significant changes, batching when possible. Include ReplayId handling for atâ€‘leastâ€‘once delivery.\n",
        "3) Middleware: Route events to microservices via topics with consumer groups. Persist to a compacted topic for latestâ€‘state lookups.\n",
        "4) Circuit Breakers: In Apex callouts and in middleware, implement timeouts, bulkheads, retry with backoff, and open/halfâ€‘open states when downstream SLAs degrade. Surface breaker state to an Ops dashboard.\n",
        "5) Error Handling: Poison message queues for nonâ€‘recoverable cases; deadâ€‘letter with full headers and correlation ids. Provide a replay utility for targeted reprocessing.\n",
        "6) Governance: Schemas in source control; semantic versioning; contract tests in CI.\n",
        "\n",
        "Outcome: API errors drop 72%, mean time to recovery improves from hours to minutes, and release risk is reduced because integrations are decoupled and observable.\"\"\",\n",
        "]\n",
        "\n",
        "negotiation_skill = [\n",
        "    \"\"\"Title: MEDDPICC Qualification Deep Dive with Evidenceâ€‘Backed Metrics\n",
        "\n",
        "Context: Enterprise opportunity (~$1.2M ARR) with a multinational manufacturer. Forecast accuracy is under scrutiny; leadership wants verifiable qualification, not optimism.\n",
        "\n",
        "Approach:\n",
        "1) Metrics: Quantify business impact with customer mathâ€”e.g., â€œReduce scrap rate by 0.8% â†’ $2.4M/year savings; breakeven in 6.1 months.â€ Validate with their baseline data and finance approval.\n",
        "2) Economic Buyer: Identify EB by budget authority and strategic initiative ownership; confirm via org chart and calendar access. Secure a 30â€‘minute â€œvalue hypothesisâ€ review and capture an endorsement quote.\n",
        "3) Decision Criteria: Map technical (security, uptime, TTV), commercial (TCO 3 years), and relationship factors (local support). Score against competing options using a weighted rubric and share transparently.\n",
        "4) Decision Process: Timeline with stage gates (pilot â†’ security review â†’ legal â†’ CFO). Define exit criteria for each stage and the documents needed.\n",
        "5) Paper Process: Preâ€‘align redlines with Legal; propose mutual NDA, dataâ€‘processing addendum, and order form structure before the final sprint to avoid lastâ€‘minute stalls.\n",
        "6) Identified Pain: Tie pains to quantified cost (e.g., unplanned downtime = $18k/hr).\n",
        "\n",
        "Tools & Artifacts: Oneâ€‘page MEDDPICC scorecard in CRM, stakeholder map, risk register, and mutual action plan (MAP) shared with the customer.\n",
        "\n",
        "Outcome: Deal forecast moves from â€œBest Caseâ€ to â€œCommit.â€ Close plan aligns internal/external teams; CFO support shortens paper cycle from 4 weeks to 10 days.\"\"\",\n",
        "    \"\"\"Title: Challenger Commercial Teaching Narrative that Reframes Status Quo\n",
        "\n",
        "Context: A prospect believes their homegrown system is â€œgood enough.â€ We must teach them a disruptive insight that links an unconsidered problem to our distinct approach.\n",
        "\n",
        "Structure (Three Acts):\n",
        "1) Warm the Rational: Start with industry trend data showing invisible costs (e.g., fragmented demand signals). Use their metrics to translate risk into dollars.\n",
        "2) Reframe: Reveal the â€œhidden causeâ€â€”decision latency across handâ€‘offsâ€”which compounds error rates. Present a mental model (Leadâ€‘toâ€‘Revenue Loop) that spotlights the bottleneck.\n",
        "3) Introduce the New Way: Position our platform as the logical next stepâ€”shared data plane, realâ€‘time scoring, and automated playbooksâ€”illustrated by a before/after dayâ€‘inâ€‘theâ€‘life.\n",
        "\n",
        "Proof: Social proof from a peer logo, concrete KPI lift (e.g., +19% win rate), and a short pilot plan with objective success criteria.\n",
        "\n",
        "Call to Action: â€œ90â€‘day pilot with three workflowsâ€ tied to financeâ€‘validated ROI. Deâ€‘risk with executive sponsorship and success office hours.\n",
        "\n",
        "Outcome: Prospect moves from curiosity to urgency; they dismantle internal objections themselves because the cost of inaction is made explicit.\"\"\",\n",
        "    \"\"\"Title: Valueâ€‘Based Pricing with ROI Model and Asymmetric Tiering\n",
        "\n",
        "Context: We are launching usageâ€‘based packaging. We must anchor price to economic value, not to costâ€‘plus, and avoid raceâ€‘toâ€‘theâ€‘bottom discounting.\n",
        "\n",
        "Method:\n",
        "1) Value Model: Build a driver tree linking product levers (automation hours saved, conversion lift, churn reduction) to EBITDA. Calibrate with customer inputs and sensitivity ranges.\n",
        "2) Tiers: Goodâ€‘Betterâ€‘Best with a â€œdecoyâ€ tier that nudges selection (e.g., mid tier offers 80% of flagship features; top tier adds governance and analytics). Meter limits match willingness to pay.\n",
        "3) Fences: Roleâ€‘based access and compliance features reserved for enterprise to preserve ARPU. Publish overage rates that are predictable and fair.\n",
        "4) Packaging Rules: Bundle features that create complementarity; unbundle highâ€‘value analytics as addâ€‘ons.\n",
        "5) Negotiation: Use ROI proof (payback < 6 months) to defend list. Convert discount asks into earned concessions (longer term, case study, reference calls).\n",
        "\n",
        "Outcome: ASP increases 12â€“18% while churn risk is mitigated; sales gains confidence because pricing is defensible with math, not handâ€‘waving.\"\"\",\n",
        "    \"\"\"Title: Objection Handling Playbook by Objection Type with Conversational Tactics\n",
        "\n",
        "Context: Lateâ€‘stage deals surface recurring objectionsâ€”Skepticism, Budget, Priority, and Competitive. Reps need precise language and evidence to respond succinctly.\n",
        "\n",
        "Framework:\n",
        "â€¢ Skepticism: Use Feelâ€‘Feltâ€‘Found and thirdâ€‘party validation (â€œI understand how you feel; Acme felt the sameâ€¦ they found deployment took 10 days and cut errors 23%â€). Offer a 2â€‘hour technical deepâ€‘dive to prove it.\n",
        "â€¢ Budget: Quantify opportunity cost (â€œA 2â€‘point churn improvement equals $X ARR this quarterâ€). Present phased rollout to align spend with realized value.\n",
        "â€¢ Priority: Tie to CEO agenda; show cost of delay. Propose a pilot that runs in parallel, not instead of other initiatives.\n",
        "â€¢ Competitor: Avoid feature war; contrast outcomes and risk. Use a pointâ€‘byâ€‘point scorecard only after reâ€‘anchoring on business value.\n",
        "\n",
        "Enablement: A searchable library of 30 second â€œanswer clips,â€ customer quotes, and miniâ€‘demos mapped to each objection. Call recording snippets become coaching content.\n",
        "\n",
        "Outcome: Objection cycles shrink; winâ€‘rates improve without resorting to discounting as the first lever.\"\"\",\n",
        "    \"\"\"Title: Consensus Building Across a Buying Committee Using Power/Interest Mapping\n",
        "\n",
        "Context: A 12â€‘person committee includes CIO, CISO, RevOps, Finance, Legal, and field users. Misaligned incentives stall decisions.\n",
        "\n",
        "Plan:\n",
        "1) Map stakeholders into a Power/Interest grid; classify champions, blockers, and neutrals. Capture â€œWhatâ€™s In It For Meâ€ (WIIFM) for each.\n",
        "2) Craft personalized value messages: CISO (risk reduction), Finance (predictable cost), RevOps (operational speed), Users (less admin work).\n",
        "3) Sequence meetings: Start with highâ€‘power/highâ€‘interest to coâ€‘create success metrics, then expand to wider group with champions present.\n",
        "4) Artifacts: Mutual Action Plan with owner per task; decision log that documents agreements; exec summary PDF for asynchronous alignment.\n",
        "5) Executive Readout: Present tradeâ€‘offs and the recommended path with quantified ROI and risk mitigation.\n",
        "\n",
        "Outcome: The committee converges on shared evaluation criteria and timeline; political friction decreases because each stakeholder sees personal benefit explicitly addressed.\"\"\",\n",
        "]\n",
        "\n",
        "product_knowledge_skill = [\n",
        "    \"\"\"Title: Multiâ€‘Tenancy Choices and PostgreSQL Rowâ€‘Level Security in Enterprise SaaS\n",
        "\n",
        "Context: A new enterprise edition must isolate tenants while controlling costs. We compare schemaâ€‘perâ€‘tenant, shared schema with RLS, and databaseâ€‘perâ€‘tenant.\n",
        "\n",
        "Decision:\n",
        "1) Start with shared schema + RLS (Rowâ€‘Level Security) for moderate scale; promote heavy tenants to dedicated schemas as needed.\n",
        "2) Implement RLS policies such as: CREATE POLICY tenant_isolation ON public.records USING (tenant_id = current_setting('app.tenant_id')::uuid);\n",
        "3) Session Management: Set app.tenant_id via a secure connection parameter (no user input).\n",
        "\n",
        "Partitioning & Performance:\n",
        "â€¢ PARTITION BY LIST (tenant_id) for operational tables with hot tenants; or PARTITION BY RANGE (created_at) for timeâ€‘series heavy workloads.\n",
        "â€¢ Use covering indexes per tenant hot paths; analyze bloat and VACUUM regularly.\n",
        "\n",
        "Operational Controls:\n",
        "â€¢ Encrypt at rest (KMS CMKs), pgcrypto for fieldâ€‘level PII, and periodic key rotation.\n",
        "â€¢ Backup/restore with PITR; offer tenantâ€‘level export for compliance.\n",
        "â€¢ Observability tags include tenant_id in logs and metrics.\n",
        "\n",
        "Outcome: We achieve isolation with a single codebase, predictable query performance, and a path to graduate large tenants with minimal migration overhead.\"\"\",\n",
        "    \"\"\"Title: Usageâ€‘Based Pricing Pipeline with Kafka, Stream Aggregations, and Tiered Billing\n",
        "\n",
        "Context: The product bills on events (jobs executed, tokens used). Billing must be accurate, auditable, and near realâ€‘time with customerâ€‘visible usage dashboards.\n",
        "\n",
        "Pipeline:\n",
        "1) Ingestion: Produce events as {tenant_id, event_type, quantity, timestamp, idempotency_key}. Use partitioning by tenant_id for ordering.\n",
        "2) Stream Processing: Kafka Streams (or Flink) aggregates in sliding/tumbling windows (hour/day). Maintain running totals per customer and detect anomalies (sudden spikes).\n",
        "3) Tiering: Apply rate tables and committedâ€‘use discounts. On window close, emit usage summaries to a billing topic.\n",
        "4) Storage: Sink to a columnar warehouse (e.g., BigQuery/Snowflake) for analytics and to a ledger DB for financial integrity.\n",
        "5) Customer Portal: Surface near realâ€‘time usage with sparklines, forecasted bill, and alerts when approaching limits.\n",
        "\n",
        "Controls: Exactlyâ€‘once semantics with idempotent producers; replay support; reconciliation jobs compare ledger vs. warehouse counts.\n",
        "\n",
        "Outcome: Finance trusts the numbers; customers see fair, transparent billing; support tickets about â€œmystery overagesâ€ drop dramatically.\"\"\",\n",
        "    \"\"\"Title: Security Architecture for SOC 2 with SSO (OAuth2/SAML) and Fineâ€‘Grained RBAC\n",
        "\n",
        "Context: We target SOC 2 Type II. Security must be by design, not boltâ€‘on.\n",
        "\n",
        "Pillars:\n",
        "1) Identity: Support SSO via OAuth 2.0 (OIDC) and SAML 2.0. Map IdP groups to app roles (Admin, Analyst, ReadOnly). Enforce MFA at IdP; short session lifetimes with refresh tokens.\n",
        "2) Data Protection: Encrypt at rest with KMS CMKs; TLS 1.2+ in transit; fieldâ€‘level encryption for PII. Add retention policies and secure deletion workflows.\n",
        "3) RBAC: Resourceâ€‘level permissions with policy engine (e.g., OPA) evaluated per request; audit all decisions.\n",
        "4) Secure SDLC: Dependency scanning, SAST/DAST, and mandatory code review. Production access via breakâ€‘glass with approvals.\n",
        "\n",
        "Outcome: Auditors verify controls; customers gain confidence, accelerating security questionnaires and enterprise deals.\"\"\",\n",
        "    \"\"\"Title: Microservices with DDD, API Gateway, and Istio Service Mesh for mTLS\n",
        "\n",
        "Context: Monolith is slowing teams; we move to microservices without losing reliability.\n",
        "\n",
        "Approach:\n",
        "1) Domainâ€‘Driven Design: Bounded contexts (Billing, Identity, Workflow). Each service owns its data.\n",
        "2) Gateway: Kong (or equivalent) provides routing, auth, rateâ€‘limits, and request/response transformations. Public APIs are versioned and documented.\n",
        "3) Mesh: Istio enforces mTLS, retries, timeouts, circuit breaking; traffic shifting enables safe deploys. Central observability (OpenTelemetry â†’ Grafana/Tempo/Loki).\n",
        "\n",
        "Outcome: Teams deploy independently with reduced blast radius; SLOs improve via meshâ€‘level resilience.\"\"\",\n",
        "    \"\"\"Title: Onboarding Optimization with Progressive Profiling and Guided Tours\n",
        "\n",
        "Context: Activation is flat. Users abandon during setup because we ask for too much too soon and do not show value fast enough.\n",
        "\n",
        "Plan:\n",
        "1) Progressive Profiling: Ask only essentials at signup; collect advanced fields later based on inâ€‘app behavior.\n",
        "2) Provisioning: Automate workspace creation upon payment webhooks; seed with sample data to make dashboards meaningful on day one.\n",
        "3) Inâ€‘App Education: Contextual tooltips, checklists, and a â€œfirst winâ€ tour that finishes in < 5 minutes. Personalize steps based on role.\n",
        "4) Measurement: Define Activation = complete 3 key actions; instrument events and build a weekly cohort dashboard.\n",
        "\n",
        "Outcome: Timeâ€‘toâ€‘Firstâ€‘Value drops by 40%; weekâ€‘4 retention climbs; support tickets on â€œhow do I start?â€ decline.\"\"\",\n",
        "]\n",
        "\n",
        "data_analytics_skill = [\n",
        "    \"\"\"Title: RFM Segmentation with Quintiles and Playbook Triggers\n",
        "\n",
        "Context: Marketing needs targeted plays by customer value. We will compute Recency, Frequency, and Monetary scores at the customer level, then assign segments and trigger actions.\n",
        "\n",
        "SQL Outline:\n",
        "1) Compute recency_days = CURRENT_DATE â€“ last_order_date; frequency = count(orders); monetary = sum(net_revenue).\n",
        "2) Use NTILE(5) over appropriate ordering to assign R, F, M quintiles (R is reversedâ€”lower days = higher score).\n",
        "3) Concatenate segment_code = CONCAT('R',R,'F',F,'M',M).\n",
        "\n",
        "Segments & Plays:\n",
        "â€¢ R5F5M5 â€œChampionsâ€: early access + VIP support.\n",
        "â€¢ R3F4M5 â€œLoyal Big Spendersâ€: crossâ€‘sell bundles.\n",
        "â€¢ R2F2M2 â€œAt Riskâ€: winâ€‘back with timeâ€‘boxed offers.\n",
        "â€¢ R1F1M1 â€œHibernatingâ€: nurture content and reactivation surveys.\n",
        "\n",
        "Validation: Check stability across time; ensure no segment is empty due to skew. Feed results into a CDP for execution and maintain a dashboard for movement between segments.\n",
        "\n",
        "Outcome: Conversion on targeted campaigns doubles vs. sprayâ€‘andâ€‘pray; sales focuses on highâ€‘propensity cohorts.\"\"\",\n",
        "    \"\"\"Title: Predictive Churn with XGBoost, Imbalance Handling, and Probability Calibration\n",
        "\n",
        "Context: With monthly churn at 3.1%, leadership wants a proactive save motion. We will ship a model that predicts churn risk 30 days ahead.\n",
        "\n",
        "Pipeline:\n",
        "1) Feature Engineering: rolling_7/30d activity, feature usage vectors, ticket sentiment, timeâ€‘sinceâ€‘lastâ€‘value, billing signals, and NPS history.\n",
        "2) Train: XGBoost with class_weighting; compare with focal loss variant. Use timeâ€‘based splits to mimic production drift.\n",
        "3) Imbalance: SMOTE for training only (on train fold). Evaluate with PRâ€‘AUC and recall@topâ€‘k.\n",
        "4) Calibration: Isotonic regression to make probabilities actionable.\n",
        "5) Ops: Weekly batch scores; trigger save playbooks (customer success outreach, enablement content).\n",
        "\n",
        "Outcome: Save rate increases; CSAT improves because outreach is timely and relevant.\"\"\",\n",
        "    \"\"\"Title: Cohort Retention and LTV with Discounted Cash Flows\n",
        "\n",
        "Context: Finance needs LTV by acquisition cohort to steer CAC spend.\n",
        "\n",
        "Method:\n",
        "1) Group users by signup_month; compute cohort tables with active rates over time (DATE_TRUNC and window functions).\n",
        "2) Estimate revenue per active user; multiply by retention to get monthly cash flows.\n",
        "3) Discount future cash flows (WACC) to compute LTV; provide confidence intervals via bootstrap.\n",
        "\n",
        "Outcome: Marketing reallocates budget to cohorts with superior payback; pricing experiments are evaluated with a sound financial lens.\"\"\",\n",
        "    \"\"\"Title: Multiâ€‘Touch Attribution (Positionâ€‘Based + MMM) for Budget Rebalance\n",
        "\n",
        "Context: Disagreement persists between teams on what channels drive revenue. We combine a positionâ€‘based (40â€‘20â€‘40) model for microâ€‘level visibility with Marketing Mix Modeling for macro budget decisions.\n",
        "\n",
        "Steps:\n",
        "1) Build a clean touchpoint table; deâ€‘duplicate via user_id + timestamp windows.\n",
        "2) Compute positionâ€‘based credits per journey; roll up by channel and campaign.\n",
        "3) Fit a regression MMM on weekly spend vs. outcomes with adstock and saturation.\n",
        "4) Compare ROI by channel; simulate reallocation scenarios.\n",
        "\n",
        "Outcome: Budget shifts from underperforming channels to highâ€‘ROI ones; leadership trusts the numbers because both micro and macro lenses are consistent.\"\"\",\n",
        "    \"\"\"Title: Product Analytics with Event Instrumentation and Funnel Analysis\n",
        "\n",
        "Context: The team needs clarity on activation and dropâ€‘off. We will standardize event tracking and build funnels and activation metrics.\n",
        "\n",
        "Plan:\n",
        "1) Instrument events via Segment: {event_name, timestamp, user_id, properties}. Enforce a tracking plan and schema linting.\n",
        "2) Define activation (e.g., invited a teammate + created first workflow + integrated data source).\n",
        "3) Build funnels in the BI tool; calculate stepâ€‘toâ€‘step conversion and timeâ€‘toâ€‘convert.\n",
        "4) Prioritize fixes where impact Ã— effort is highest.\n",
        "\n",
        "Outcome: Activation improves through targeted UX changes; PMs make decisions with trustworthy, consistent data.\"\"\",\n",
        "]\n",
        "\n",
        "communication_skill = [\n",
        "    \"\"\"Title: PAS Email Sequence (5 Touches) for Enterprise Prospecting\n",
        "\n",
        "Context: Cold outbound to VPâ€‘level personas at Fortune 1000. Goal is 1) open â†’ meeting and 2) minimal friction for reply.\n",
        "\n",
        "Sequence:\n",
        "1) Email 1 (Problem): 140â€“160 words. Hyperâ€‘specific pain tied to their role; one bolded stat; one link to value proof; one question CTA.\n",
        "2) Email 2 (Agitate): 120â€“140 words. Illustrate hidden costs and operational drag with a short vignette.\n",
        "3) Email 3 (Social Proof): 100â€“120 words. Two logos, one quote, and a clear KPI.\n",
        "4) Email 4 (Content): 90â€“110 words. Share a practical resource (calculator or checklist) with no hard sell.\n",
        "5) Email 5 (Breakup): 60â€“80 words. Respectful exit with a â€œShould I close your file?â€ CTA.\n",
        "\n",
        "Crafting Notes: Subject lines under 45 characters; preview text complements subject; avoid link overload; personalize the first 20 words.\n",
        "\n",
        "Outcome: Reply rates increase to 6â€“9% in target segments; meetings booked with qualified prospects without heavy discounting.\"\"\",\n",
        "    \"\"\"Title: SPIN Discovery Call Script for Complex Sales\n",
        "\n",
        "Context: 45â€‘minute first discovery with crossâ€‘functional stakeholders.\n",
        "\n",
        "Flow:\n",
        "1) Situation: Establish baseline systems, team structure, KPIs.\n",
        "2) Problem: Elicit pain with drilling questions; quantify frequency/severity.\n",
        "3) Implication: Surface secondâ€‘order effects; calculate cost of inaction.\n",
        "4) Needâ€‘Payoff: Coâ€‘create success metrics and define the first pilot.\n",
        "5) Next Steps: Summarize, confirm timeline, assign owners to actions.\n",
        "\n",
        "Outcome: You leave with a validated problem statement, quantifiable value hypothesis, and agreed next stepsâ€”fuel for a winning proposal.\"\"\",\n",
        "    \"\"\"Title: Executive Business Review (EBR) Using Situationâ€‘Complicationâ€‘Resolution\n",
        "\n",
        "Context: Quarterly EBR with an enterprise customer to confirm outcomes and propose expansion.\n",
        "\n",
        "Structure:\n",
        "â€¢ Situation: Where we started (baseline metrics).\n",
        "â€¢ Complication: New constraints (market, headcount, security).\n",
        "â€¢ Resolution: What we delivered, with customerâ€‘owned data; present deltas vs. baseline.\n",
        "â€¢ Expansion: Roadmap aligned to their goals; quantified upside; request executive sponsorship.\n",
        "\n",
        "Outcome: Renewal progresses smoothly; expansion is framed as the rational continuation of delivered value.\"\"\",\n",
        "    \"\"\"Title: Support Ticket Responses with AIR (Acknowledgeâ€‘Investigateâ€‘Resolve)\n",
        "\n",
        "Context: Severityâ€‘1 incident affecting a subset of customers.\n",
        "\n",
        "Template:\n",
        "â€¢ Acknowledge: Within 15 minutes; share incident id, blast radius, and next update time.\n",
        "â€¢ Investigate: Outline repro steps, telemetry, and suspected root causes; avoid speculation.\n",
        "â€¢ Resolve: Document the fix, backout plan if needed, and followâ€‘up actions (postâ€‘mortem, credits).\n",
        "\n",
        "Outcome: Customers trust the process; CSAT remains high despite incidents; internal learning compounds via blameless postâ€‘mortems.\"\"\",\n",
        "    \"\"\"Title: Objection Scripts for Price, Feature Gap, Timing, and Competitor\n",
        "\n",
        "Context: Standardize responses so reps sound confident and concise.\n",
        "\n",
        "Scripts:\n",
        "â€¢ Price: â€œLetâ€™s anchor on ROIâ€”hereâ€™s what payback looks like. If we phase rollout, we can align spend to realized value.â€\n",
        "â€¢ Feature Gap: â€œYouâ€™re right that X isnâ€™t available today. Hereâ€™s the workaround and the roadmap checkpoint; would a pilot validate the approach?â€\n",
        "â€¢ Timing: â€œWhat decision criteria would make this quarter the right time? We can deâ€‘risk with a limitedâ€‘scope pilot.â€\n",
        "â€¢ Competitor: â€œFeature lists aside, hereâ€™s what customers achieve with us and the risks we remove. Would you evaluate outcomes sideâ€‘byâ€‘side?â€\n",
        "\n",
        "Outcome: Objections are reframed constructively; momentum continues without defensive postures.\"\"\",\n",
        "]\n",
        "\n",
        "compliance_skill = [\n",
        "    \"\"\"Title: GDPR Lawful Basis, LIA, and Data Subject Rights at Scale\n",
        "\n",
        "Context: CRM processes personal data for EEA residents. We must document lawful basis and handle DSARs within statutory windows.\n",
        "\n",
        "Plan:\n",
        "1) Lawful Basis: Map processing to Article 6. For CRM outreach, rely on Legitimate Interests with a documented LIA (purpose, necessity, balancing test) and optâ€‘out controls.\n",
        "2) DSAR Workflow: Intake portal with identity verification; route to Data Steward queue; 30â€‘day clock with extensions documented.\n",
        "3) Data Minimization: Collect only necessary fields; define retention periods; purge stale data with automated jobs.\n",
        "4) Records of Processing: Maintain RoPA; keep vendor DPA inventory current.\n",
        "\n",
        "Outcome: Regulators and customers see robust governance; marketing operates confidently within legal bounds.\"\"\",\n",
        "    \"\"\"Title: CANâ€‘SPAM with SPF/DKIM/DMARC and Listâ€‘Unsubscribe\n",
        "\n",
        "Context: Outbound emails must comply and preserve deliverability.\n",
        "\n",
        "Controls:\n",
        "1) Authenticate mail (SPF, DKIM) and enforce DMARC p=quarantine/noneâ†’reject over time.\n",
        "2) Clear identification of sender and postal address; truthful subject lines.\n",
        "3) Functional Listâ€‘Unsubscribe header; process optâ€‘outs within 10 days across all systems.\n",
        "4) Monitor bounce/complaint rates; remediate with list hygiene.\n",
        "\n",
        "Outcome: Fewer spam traps and higher inbox placement; legal and reputation risks are reduced.\"\"\",\n",
        "    \"\"\"Title: SOC 2 Type II Readiness with TSC Controls and Continuous Monitoring\n",
        "\n",
        "Context: We target audit within 12 months.\n",
        "\n",
        "Controls & Evidence:\n",
        "1) Governance: Risk Committee, policies, and quarterly reviews.\n",
        "2) Access: RBAC, least privilege, quarterly access recertification.\n",
        "3) Change Mgmt: CI/CD with approvals, artifact retention.\n",
        "4) Security Ops: SIEM with daily triage, vulnerability scans, patch SLAs.\n",
        "5) DR/BCP: Tested runbooks and RTO/RPO objectives.\n",
        "\n",
        "Outcome: Clean audit opinion; faster enterprise deals; a culture of operational discipline.\"\"\",\n",
        "    \"\"\"Title: PCI DSS Scope Reduction and Encryption for Payment Data\n",
        "\n",
        "Context: We handle card data via a thirdâ€‘party gateway but must ensure our environment is compliant.\n",
        "\n",
        "Steps:\n",
        "1) Network Segmentation: Isolate CDE and restrict access; jump hosts only.\n",
        "2) Tokenization: Never store PANs; rely on gateway tokens; if PAN appears transiently, encrypt with AESâ€‘256 using KMS, rotate keys, and restrict access.\n",
        "3) Quarterly ASV scans and annual penetration tests; remediate findings promptly.\n",
        "4) Logging: Centralize and retain with tamperâ€‘evidence.\n",
        "\n",
        "Outcome: Audit scope is reduced, risk declines, and payment operations remain reliable.\"\"\",\n",
        "    \"\"\"Title: CCPA Consumer Rights, Notice at Collection, and Doâ€‘Notâ€‘Sell\n",
        "\n",
        "Context: Serving California residents requires transparency and control.\n",
        "\n",
        "Program:\n",
        "1) Notice at Collection: Clear disclosures of categories and purposes at the point of data entry.\n",
        "2) Rights Requests: 45â€‘day SLA with identity verification; maintain a case system with audit trails.\n",
        "3) Doâ€‘Notâ€‘Sell/Share: Honor signals (GPC); propagate preferences to all processors.\n",
        "4) Training: Annual refreshers for customerâ€‘facing teams.\n",
        "\n",
        "Outcome: Reduced regulatory risk and increased consumer trust; marketing remains effective within the rules.\"\"\",\n",
        "]\n",
        "\n",
        "print(f'âœ… Loaded 6 skills = comprehensive training datasets')\n",
        "print(f'   Each example: 300-500 words of technical depth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“ Training Universal Adapters - The Core UAL Process\n",
        "\n",
        "### ğŸ¯ **What This Cell Does**\n",
        "This is where the **magic happens**! This cell:\n",
        "1. Loads GPT-2 as the training model\n",
        "2. Trains 6 specialized LoRA adapters (one for each skill)\n",
        "3. Exports them to **AIR format** (Architecture-Agnostic Intermediate Representation)\n",
        "4. Creates portable files that work across ANY model architecture\n",
        "\n",
        "### ğŸ§  **Why This Is Revolutionary**\n",
        "- **Traditional:** Train adapter on GPT-2 â†’ Only works on GPT-2 âŒ\n",
        "- **UAL:** Train adapter on GPT-2 â†’ Works on GPT-2, LLaMA, Qwen, Mistral, etc. âœ…\n",
        "\n",
        "### ğŸ“¦ **What Gets Created**\n",
        "A `skills/` folder with 6 AIR files:\n",
        "```\n",
        "skills/crm_mastery.air\n",
        "skills/negotiation.air\n",
        "skills/product_knowledge.air\n",
        "skills/data_analytics.air\n",
        "skills/communication.air\n",
        "skills/compliance.air\n",
        "```\n",
        "\n",
        "Each `.air` file is a **universal adapter** ready for any model!\n",
        "\n",
        "---\n",
        "\n",
        "### âš™ï¸ **Training Parameters**\n",
        "\n",
        "- **`rank=8`** - Adapter size (higher = more powerful but larger)\n",
        "- **`alpha=16`** - Scaling factor (typically 2Ã— rank)\n",
        "- **`epochs=1`** - Training passes (1 is enough for quality data)\n",
        "- **`batch_size=1`** - Process 1 example at a time (memory efficient)\n",
        "- **`target_modules`** - Which model layers to adapt\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ **What Happens**\n",
        "\n",
        "**For each skill:**\n",
        "1. Train adapter using skill examples\n",
        "2. Convert to architecture-agnostic AIR format\n",
        "3. Save portable `.air` file\n",
        "4. Show progress\n",
        "\n",
        "**After all skills:**\n",
        "- Clean GPU memory\n",
        "- Display summary\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¡ **The UAL Innovation**\n",
        "AIR files store adapter weights but NOT the base model - that's why they're portable!\n",
        "\n",
        "When loading into a different model, UAL:\n",
        "1. Reads the adapter structure\n",
        "2. Maps to the new model's architecture\n",
        "3. Handles dimension mismatches automatically\n",
        "4. Injects the knowledge\n",
        "\n",
        "### ğŸ“ **Key Concept: Train Once, Deploy Everywhere**\n",
        "Training on GPT-2 (small, fast), but these adapters work on TinyLLaMA, Qwen, SmolLM, and any future model!\n",
        "\n",
        "---\n",
        "\n",
        "### â±ï¸ **Expected Time**\n",
        "**1-2 minutes** on T4 GPU\n",
        "\n",
        "### âœ… **Success Indicators**\n",
        "```\n",
        "âœ… Created skills/ directory\n",
        "Loading GPT-2 as source model...\n",
        "Training 6 CRM skills...\n",
        "[crm_mastery] Training...\n",
        "  âœ“ Exported to skills/crm_mastery.air\n",
        "...\n",
        "âœ… All 6 skills trained and exported!\n",
        "âœ… Memory cleaned\n",
        "```\n"
      ],
      "metadata": {
        "id": "eatiNhZnrQQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from ual_adapter import UniversalAdapter\n",
        "import gc\n",
        "\n",
        "# Create folder for AIR files\n",
        "os.makedirs('skills', exist_ok=True)\n",
        "print('âœ… Created skills/ directory\\n')\n",
        "\n",
        "# Load GPT-2 for training\n",
        "print('Loading GPT-2 as source model...')\n",
        "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Initialize UAL Adapter\n",
        "ual = UniversalAdapter(\n",
        "    base_model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device='auto'\n",
        ")\n",
        "\n",
        "# Organize all skills\n",
        "skills = {\n",
        "    'crm_mastery': crm_mastery_skill,\n",
        "    'negotiation': negotiation_skill,\n",
        "    'product_knowledge': product_knowledge_skill,\n",
        "    'data_analytics': data_analytics_skill,\n",
        "    'communication': communication_skill,\n",
        "    'compliance': compliance_skill\n",
        "}\n",
        "\n",
        "# Train each skill and export to AIR\n",
        "print(f'\\n{\"=\"*70}')\n",
        "print(f'Training {len(skills)} CRM skills...')\n",
        "print(f'{\"=\"*70}\\n')\n",
        "\n",
        "for skill_name, training_data in skills.items():\n",
        "    print(f'[{skill_name}] Training...')\n",
        "\n",
        "    # Train the adapter\n",
        "    ual.train_adapter(\n",
        "        adapter_name=skill_name,\n",
        "        training_data=training_data,\n",
        "        rank=8,\n",
        "        alpha=16,\n",
        "        epochs=1,\n",
        "        batch_size=1,\n",
        "        target_modules=['c_attn', 'c_proj']\n",
        "    )\n",
        "\n",
        "    # Export to AIR format\n",
        "    air_path = f'skills/{skill_name}.air'\n",
        "    ual.export_adapter(skill_name, air_path)\n",
        "    print(f'  âœ“ Exported to {air_path}\\n')\n",
        "\n",
        "# Summary\n",
        "print('='*70)\n",
        "print('âœ… All 6 skills trained and exported!')\n",
        "print('='*70)\n",
        "print('\\nAIR files created:')\n",
        "for skill in skills.keys():\n",
        "    print(f'  â€¢ skills/{skill}.air')\n",
        "\n",
        "# Clean up memory\n",
        "del model, ual\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print('\\nâœ… Memory cleaned')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saMN8DWNrxyj",
        "outputId": "7fb731be-43cd-40b1-e5c7-1bcff95f3b85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Created skills/ directory\n",
            "\n",
            "Loading GPT-2 as source model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:04.729\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.730\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptj'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.730\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-j'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.731\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.732\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.732\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.733\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'codellama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.733\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'pythia'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.734\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-neox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.734\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptneox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.735\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.736\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.736\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mistral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.737\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mixtral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.737\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.738\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.738\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.739\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'bert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.739\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'roberta'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.739\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'distilbert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.740\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.740\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5-base'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.741\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mt5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.741\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'generic'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.742\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'unknown'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36m_register_default_binders\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mRegistered 25 default binders\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mInitialized UAL for gpt2 model with 124,439,808 parameters\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mTraining adapter 'crm_mastery'...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mTraining adapter... (simplified implementation)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mâœ… Trained adapter 'crm_mastery' with 72 weights\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.800\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.802\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.802\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.803\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.804\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.804\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.805\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.805\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.805\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.806\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.806\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.808\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.808\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.810\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.810\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.810\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.811\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.811\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.812\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.812\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.813\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.814\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.814\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.815\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.815\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.816\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.817\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.817\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.819\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.819\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.821\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.821\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.822\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.822\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.823\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.823\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.824\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.825\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.825\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.826\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.826\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.827\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.827\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.827\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.828\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.828\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.829\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.833\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.833\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.834\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.834\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.835\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.835\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.835\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.836\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.836\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.837\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.837\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.839\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.839\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mExported adapter to AIR format: skills/crm_mastery.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mexport_adapter\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mâœ… Exported adapter 'crm_mastery' to skills/crm_mastery.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mTraining adapter 'negotiation'...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mTraining adapter... (simplified implementation)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mâœ… Trained adapter 'negotiation' with 72 weights\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.892\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.892\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.893\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.894\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.894\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.895\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.895\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.895\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.896\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.896\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.897\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.897\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.897\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.898\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.899\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.899\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.901\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.901\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.902\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.902\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.903\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.903\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.904\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.904\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.904\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.905\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.905\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.905\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.906\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.906\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.907\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.907\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.907\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.908\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.908\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.912\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.912\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.912\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.913\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.913\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.915\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.915\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.916\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.916\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.916\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.917\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.917\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.917\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.918\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.918\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.919\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.919\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.920\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.922\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.922\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.923\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mExported adapter to AIR format: skills/negotiation.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mexport_adapter\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mâœ… Exported adapter 'negotiation' to skills/negotiation.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mTraining adapter 'product_knowledge'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Training 6 CRM skills...\n",
            "======================================================================\n",
            "\n",
            "[crm_mastery] Training...\n",
            "  âœ“ Exported to skills/crm_mastery.air\n",
            "\n",
            "[negotiation] Training...\n",
            "  âœ“ Exported to skills/negotiation.air\n",
            "\n",
            "[product_knowledge] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:04.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mTraining adapter... (simplified implementation)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mâœ… Trained adapter 'product_knowledge' with 72 weights\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.982\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.982\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.983\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.983\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.984\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.984\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.985\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.986\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.987\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.987\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.987\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.990\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.990\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.994\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.994\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.996\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:04.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.000\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.000\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.001\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.001\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.002\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.002\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.006\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.007\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.007\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.008\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.008\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.009\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.009\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.010\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.011\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.011\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.012\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.012\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.012\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.014\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.014\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.015\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.015\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.015\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.016\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.016\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.017\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.018\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.019\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.019\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mExported adapter to AIR format: skills/product_knowledge.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mexport_adapter\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mâœ… Exported adapter 'product_knowledge' to skills/product_knowledge.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mTraining adapter 'data_analytics'...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mTraining adapter... (simplified implementation)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mâœ… Trained adapter 'data_analytics' with 72 weights\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.069\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.070\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.070\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.071\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.072\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.072\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.073\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.074\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.074\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.075\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.075\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.076\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.078\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.078\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.079\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.079\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.080\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.085\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.085\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.086\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.086\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.092\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.092\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.093\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.093\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.094\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.094\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.094\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.095\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.095\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.096\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.096\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.099\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.099\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.100\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.100\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.101\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.101\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.101\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.102\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.102\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.102\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.103\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.103\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.103\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.104\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.104\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.105\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.105\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.105\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mExported adapter to AIR format: skills/data_analytics.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mexport_adapter\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mâœ… Exported adapter 'data_analytics' to skills/data_analytics.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mTraining adapter 'communication'...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mTraining adapter... (simplified implementation)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mâœ… Trained adapter 'communication' with 72 weights\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.159\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.159\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.160\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.160\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.163\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.164\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.164\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.166\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.166\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.168\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.168\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.170\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.174\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.174\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.175\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.175\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.178\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.179\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.179\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.180\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.180\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.182\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.182\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.183\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.183\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.184\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.187\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.188\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.188\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.192\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.192\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.193\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.193\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.194\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.194\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.195\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.195\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.199\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.199\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.200\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.200\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.201\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.201\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.202\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.202\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.203\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.203\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.204\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mExported adapter to AIR format: skills/communication.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mexport_adapter\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mâœ… Exported adapter 'communication' to skills/communication.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mTraining adapter 'compliance'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  âœ“ Exported to skills/product_knowledge.air\n",
            "\n",
            "[data_analytics] Training...\n",
            "  âœ“ Exported to skills/data_analytics.air\n",
            "\n",
            "[communication] Training...\n",
            "  âœ“ Exported to skills/communication.air\n",
            "\n",
            "[compliance] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:05.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mTraining adapter... (simplified implementation)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mtrain_adapter\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mâœ… Trained adapter 'compliance' with 72 weights\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight -> layer_0.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.258\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.258\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.259\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight -> layer_0.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.259\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.260\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight -> layer_1.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.261\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.261\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.262\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.263\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight -> layer_1.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.264\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.264\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight -> layer_2.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.265\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.265\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.266\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.266\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight -> layer_2.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.267\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.267\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight -> layer_3.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.268\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.269\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.269\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.270\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight -> layer_3.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.271\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.271\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight -> layer_4.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.271\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.273\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight -> layer_4.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.273\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.274\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight -> layer_5.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.274\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.275\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.275\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight -> layer_5.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight -> layer_6.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.279\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight -> layer_6.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.279\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.280\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight -> layer_7.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.280\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.281\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.281\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.281\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight -> layer_7.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.282\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.283\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight -> layer_8.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.283\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.284\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.284\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.285\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight -> layer_8.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.285\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.286\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight -> layer_9.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.286\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.287\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.287\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.288\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight -> layer_9.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.288\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.289\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight -> layer_10.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.289\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.289\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.290\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.290\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight -> layer_10.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.291\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.291\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight -> layer_11.attention_query\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.292\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.292\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.292\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.293\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mMapped base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight -> layer_11.mlp_down\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mexport_to_air\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mExported adapter to AIR format: skills/compliance.air\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:05.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mexport_adapter\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mâœ… Exported adapter 'compliance' to skills/compliance.air\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  âœ“ Exported to skills/compliance.air\n",
            "\n",
            "======================================================================\n",
            "âœ… All 6 skills trained and exported!\n",
            "======================================================================\n",
            "\n",
            "AIR files created:\n",
            "  â€¢ skills/crm_mastery.air\n",
            "  â€¢ skills/negotiation.air\n",
            "  â€¢ skills/product_knowledge.air\n",
            "  â€¢ skills/data_analytics.air\n",
            "  â€¢ skills/communication.air\n",
            "  â€¢ skills/compliance.air\n",
            "\n",
            "âœ… Memory cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¤– Setting Up Multi-Agent System - Loading Models & Skills\n",
        "\n",
        "### ğŸ¯ **What This Cell Does**\n",
        "Your **multi-agent CRM system comes to life**! This cell:\n",
        "1. Loads 4 different AI models (one for each agent)\n",
        "2. Attaches UAL adapters to each model\n",
        "3. Imports trained skills from AIR files\n",
        "4. Sets up intelligent dispatchers for skill routing\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ­ **The 4 Agents**\n",
        "\n",
        "**Sales Rep** ğŸ’¼ - Qwen2.5-0.5B\n",
        "- Skills: negotiation, communication, product_knowledge\n",
        "- Role: Leads, quotes, pricing\n",
        "\n",
        "**Support Specialist** ğŸ› ï¸ - TinyLlama-1.1B\n",
        "- Skills: communication, product_knowledge, compliance\n",
        "- Role: Technical issues, troubleshooting\n",
        "\n",
        "**Account Manager** ğŸ“Š - SmolLM2-360M\n",
        "- Skills: crm_mastery, communication, data_analytics\n",
        "- Role: Renewals, upsells, relationships\n",
        "\n",
        "**Data Analyst** ğŸ“ˆ - Qwen2.5-1.5B\n",
        "- Skills: data_analytics, crm_mastery, compliance\n",
        "- Role: Reports, metrics, analysis\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ **Process for Each Agent**\n",
        "\n",
        "1. Load base model\n",
        "2. Create UAL Adapter\n",
        "3. Import relevant AIR skills\n",
        "4. Setup intelligent dispatcher\n",
        "5. Register skills with dispatcher\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  **The Dispatcher**\n",
        "\n",
        "Each agent has a **LoRADispatcher** that:\n",
        "- Analyzes incoming queries\n",
        "- Matches to best skill\n",
        "- Dynamically loads appropriate adapter\n",
        "- Uses `all-MiniLM-L6-v2` for smart routing\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **Key UAL Magic**\n",
        "\n",
        "Same `negotiation.air` works on Qwen, TinyLlama, SmolLM:\n",
        "- No retraining per model\n",
        "- Architecture differences handled automatically\n",
        "- Instant specialized knowledge\n",
        "\n",
        "---\n",
        "\n",
        "### â±ï¸ **Expected Time**\n",
        "**1-2 minutes** to load all 4 models\n",
        "\n",
        "### âœ… **Success Indicators**\n",
        "```\n",
        "Configuring Backend Models with Dispatchers\n",
        "[sales_rep] Loading...\n",
        "  âœ“ negotiation\n",
        "  âœ“ communication\n",
        "  âœ“ product_knowledge\n",
        "...\n",
        "âœ… All agents configured!\n",
        "```\n"
      ],
      "metadata": {
        "id": "8FzK-pgQsYCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from ual_adapter import UniversalAdapter\n",
        "from ual_adapter.core.dispatcher import LoRADispatcher\n",
        "\n",
        "print('='*70)\n",
        "print('Setting Up Multi-Agent CRM System')\n",
        "print('='*70)\n",
        "\n",
        "agents = {}\n",
        "\n",
        "# ============================================================================\n",
        "# AGENT 1: Sales Rep\n",
        "# ============================================================================\n",
        "print('\\n[Sales Rep] Loading Qwen2.5-0.5B...')\n",
        "\n",
        "# Load model\n",
        "sales_model = AutoModelForCausalLM.from_pretrained(\n",
        "    'Qwen/Qwen2.5-0.5B-Instruct',\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map='auto' if torch.cuda.is_available() else None,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "sales_tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct')\n",
        "if sales_tokenizer.pad_token is None:\n",
        "    sales_tokenizer.pad_token = sales_tokenizer.eos_token\n",
        "\n",
        "# Create UAL adapter\n",
        "sales_ual = UniversalAdapter(\n",
        "    base_model=sales_model,\n",
        "    tokenizer=sales_tokenizer,\n",
        "    device='auto'\n",
        ")\n",
        "\n",
        "# Create dispatcher\n",
        "sales_dispatcher = LoRADispatcher(\n",
        "    encoder_model='all-MiniLM-L6-v2',\n",
        "    confidence_threshold=0.30\n",
        ")\n",
        "\n",
        "# Import and register skills\n",
        "print('  Registering skills:')\n",
        "\n",
        "sales_ual.import_adapter('skills/negotiation.air')\n",
        "sales_dispatcher.register_domain(\n",
        "    domain_name='negotiation',\n",
        "    adapter_weights=sales_ual.adapters['negotiation'],\n",
        "    training_texts=skills['negotiation']\n",
        ")\n",
        "print('    âœ“ negotiation')\n",
        "\n",
        "sales_ual.import_adapter('skills/communication.air')\n",
        "sales_dispatcher.register_domain(\n",
        "    domain_name='communication',\n",
        "    adapter_weights=sales_ual.adapters['communication'],\n",
        "    training_texts=skills['communication']\n",
        ")\n",
        "print('    âœ“ communication')\n",
        "\n",
        "sales_ual.import_adapter('skills/product_knowledge.air')\n",
        "sales_dispatcher.register_domain(\n",
        "    domain_name='product_knowledge',\n",
        "    adapter_weights=sales_ual.adapters['product_knowledge'],\n",
        "    training_texts=skills['product_knowledge']\n",
        ")\n",
        "print('    âœ“ product_knowledge')\n",
        "\n",
        "agents['sales_rep'] = {\n",
        "    'model': sales_model,\n",
        "    'tokenizer': sales_tokenizer,\n",
        "    'ual': sales_ual,\n",
        "    'dispatcher': sales_dispatcher,\n",
        "    'config': {'model_name': 'Qwen/Qwen2.5-0.5B-Instruct'}\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# AGENT 2: Support Specialist\n",
        "# ============================================================================\n",
        "print('\\n[Support Specialist] Loading TinyLlama-1.1B...')\n",
        "\n",
        "support_model = AutoModelForCausalLM.from_pretrained(\n",
        "    'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map='auto' if torch.cuda.is_available() else None,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "support_tokenizer = AutoTokenizer.from_pretrained('TinyLlama/TinyLlama-1.1B-Chat-v1.0')\n",
        "if support_tokenizer.pad_token is None:\n",
        "    support_tokenizer.pad_token = support_tokenizer.eos_token\n",
        "\n",
        "support_ual = UniversalAdapter(\n",
        "    base_model=support_model,\n",
        "    tokenizer=support_tokenizer,\n",
        "    device='auto'\n",
        ")\n",
        "\n",
        "support_dispatcher = LoRADispatcher(\n",
        "    encoder_model='all-MiniLM-L6-v2',\n",
        "    confidence_threshold=0.30\n",
        ")\n",
        "\n",
        "print('  Registering skills:')\n",
        "\n",
        "support_ual.import_adapter('skills/communication.air')\n",
        "support_dispatcher.register_domain(\n",
        "    domain_name='communication',\n",
        "    adapter_weights=support_ual.adapters['communication'],\n",
        "    training_texts=skills['communication']\n",
        ")\n",
        "print('    âœ“ communication')\n",
        "\n",
        "support_ual.import_adapter('skills/product_knowledge.air')\n",
        "support_dispatcher.register_domain(\n",
        "    domain_name='product_knowledge',\n",
        "    adapter_weights=support_ual.adapters['product_knowledge'],\n",
        "    training_texts=skills['product_knowledge']\n",
        ")\n",
        "print('    âœ“ product_knowledge')\n",
        "\n",
        "support_ual.import_adapter('skills/compliance.air')\n",
        "support_dispatcher.register_domain(\n",
        "    domain_name='compliance',\n",
        "    adapter_weights=support_ual.adapters['compliance'],\n",
        "    training_texts=skills['compliance']\n",
        ")\n",
        "print('    âœ“ compliance')\n",
        "\n",
        "agents['support_specialist'] = {\n",
        "    'model': support_model,\n",
        "    'tokenizer': support_tokenizer,\n",
        "    'ual': support_ual,\n",
        "    'dispatcher': support_dispatcher,\n",
        "    'config': {'model_name': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'}\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# AGENT 3: Account Manager\n",
        "# ============================================================================\n",
        "print('\\n[Account Manager] Loading SmolLM2-360M...')\n",
        "\n",
        "account_model = AutoModelForCausalLM.from_pretrained(\n",
        "    'HuggingFaceTB/SmolLM2-360M-Instruct',\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map='auto' if torch.cuda.is_available() else None,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "account_tokenizer = AutoTokenizer.from_pretrained('HuggingFaceTB/SmolLM2-360M-Instruct')\n",
        "if account_tokenizer.pad_token is None:\n",
        "    account_tokenizer.pad_token = account_tokenizer.eos_token\n",
        "\n",
        "account_ual = UniversalAdapter(\n",
        "    base_model=account_model,\n",
        "    tokenizer=account_tokenizer,\n",
        "    device='auto'\n",
        ")\n",
        "\n",
        "account_dispatcher = LoRADispatcher(\n",
        "    encoder_model='all-MiniLM-L6-v2',\n",
        "    confidence_threshold=0.30\n",
        ")\n",
        "\n",
        "print('  Registering skills:')\n",
        "\n",
        "account_ual.import_adapter('skills/crm_mastery.air')\n",
        "account_dispatcher.register_domain(\n",
        "    domain_name='crm_mastery',\n",
        "    adapter_weights=account_ual.adapters['crm_mastery'],\n",
        "    training_texts=skills['crm_mastery']\n",
        ")\n",
        "print('    âœ“ crm_mastery')\n",
        "\n",
        "account_ual.import_adapter('skills/communication.air')\n",
        "account_dispatcher.register_domain(\n",
        "    domain_name='communication',\n",
        "    adapter_weights=account_ual.adapters['communication'],\n",
        "    training_texts=skills['communication']\n",
        ")\n",
        "print('    âœ“ communication')\n",
        "\n",
        "account_ual.import_adapter('skills/data_analytics.air')\n",
        "account_dispatcher.register_domain(\n",
        "    domain_name='data_analytics',\n",
        "    adapter_weights=account_ual.adapters['data_analytics'],\n",
        "    training_texts=skills['data_analytics']\n",
        ")\n",
        "print('    âœ“ data_analytics')\n",
        "\n",
        "agents['account_manager'] = {\n",
        "    'model': account_model,\n",
        "    'tokenizer': account_tokenizer,\n",
        "    'ual': account_ual,\n",
        "    'dispatcher': account_dispatcher,\n",
        "    'config': {'model_name': 'HuggingFaceTB/SmolLM2-360M-Instruct'}\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# AGENT 4: Data Analyst\n",
        "# ============================================================================\n",
        "print('\\n[Data Analyst] Loading Qwen2.5-1.5B...')\n",
        "\n",
        "analyst_model = AutoModelForCausalLM.from_pretrained(\n",
        "    'Qwen/Qwen2.5-1.5B-Instruct',\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map='auto' if torch.cuda.is_available() else None,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "analyst_tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-1.5B-Instruct')\n",
        "if analyst_tokenizer.pad_token is None:\n",
        "    analyst_tokenizer.pad_token = analyst_tokenizer.eos_token\n",
        "\n",
        "analyst_ual = UniversalAdapter(\n",
        "    base_model=analyst_model,\n",
        "    tokenizer=analyst_tokenizer,\n",
        "    device='auto'\n",
        ")\n",
        "\n",
        "analyst_dispatcher = LoRADispatcher(\n",
        "    encoder_model='all-MiniLM-L6-v2',\n",
        "    confidence_threshold=0.30\n",
        ")\n",
        "\n",
        "print('  Registering skills:')\n",
        "\n",
        "analyst_ual.import_adapter('skills/data_analytics.air')\n",
        "analyst_dispatcher.register_domain(\n",
        "    domain_name='data_analytics',\n",
        "    adapter_weights=analyst_ual.adapters['data_analytics'],\n",
        "    training_texts=skills['data_analytics']\n",
        ")\n",
        "print('    âœ“ data_analytics')\n",
        "\n",
        "analyst_ual.import_adapter('skills/crm_mastery.air')\n",
        "analyst_dispatcher.register_domain(\n",
        "    domain_name='crm_mastery',\n",
        "    adapter_weights=analyst_ual.adapters['crm_mastery'],\n",
        "    training_texts=skills['crm_mastery']\n",
        ")\n",
        "print('    âœ“ crm_mastery')\n",
        "\n",
        "analyst_ual.import_adapter('skills/compliance.air')\n",
        "analyst_dispatcher.register_domain(\n",
        "    domain_name='compliance',\n",
        "    adapter_weights=analyst_ual.adapters['compliance'],\n",
        "    training_texts=skills['compliance']\n",
        ")\n",
        "print('    âœ“ compliance')\n",
        "\n",
        "agents['data_analyst'] = {\n",
        "    'model': analyst_model,\n",
        "    'tokenizer': analyst_tokenizer,\n",
        "    'ual': analyst_ual,\n",
        "    'dispatcher': analyst_dispatcher,\n",
        "    'config': {'model_name': 'Qwen/Qwen2.5-1.5B-Instruct'}\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# Summary\n",
        "# ============================================================================\n",
        "print('\\n' + '='*70)\n",
        "print('âœ… All 4 agents configured and ready!')\n",
        "print('='*70)\n",
        "\n",
        "print('\\nAgent Summary:')\n",
        "print('  â€¢ Sales Rep: Qwen2.5-0.5B with 3 skills')\n",
        "print('  â€¢ Support Specialist: TinyLlama-1.1B with 3 skills')\n",
        "print('  â€¢ Account Manager: SmolLM2-360M with 3 skills')\n",
        "print('  â€¢ Data Analyst: Qwen2.5-1.5B with 3 skills')\n",
        "\n",
        "print('\\nâœ… Each agent has:')\n",
        "print('   â€¢ Base model loaded')\n",
        "print('   â€¢ UAL adapter configured')\n",
        "print('   â€¢ Intelligent dispatcher ready')\n",
        "print('   â€¢ Skills dynamically available')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9465a9e5ddaa4b3fb751efdedc93117d",
            "1df1f90b3ca549928d07a7dad2b86e16",
            "075aca08b2d440a68915062cc52ead1a",
            "4a456d5565d24bc9b471a24247e39039",
            "760c37e2fe3941bab2a874b0ba1f74f6",
            "e6a8677b4c4b462c8f35fb85aa5d821d",
            "b3ebba95ea854a5ca86686eb83a0cb3b",
            "6fb66f5534184146b516f782639d997d",
            "b5fe6aa11475452eb09aaf1d7f231284",
            "e3551f6a63c840d3ba7876efe3c0bc14",
            "0b3ec243827a46c0acfdc56d19bf3860",
            "aab3584101de46138c2d32dc74691de5",
            "732e8fee776e412f82fefc18dfda5738",
            "5fd52edae91149b2a2fdd4ae1d7e2dc8",
            "32b211c2c62e44b298d8acf3e73f2103",
            "264fd1076c9240edb29ada3aa3ee648d",
            "0c0545bd5228497ba4cbc090edf3c032",
            "28e6a84ec2f84b4585333faeb15410d0",
            "a6f631c4351e4d83851e461e5fd27e1b",
            "c64ba719c70844b6aa7b7a466b3cde8a",
            "d127a33e547c421689b935a186678282",
            "f3fdccf85758472989fdb77711a3083a",
            "c36d0a05f1944155b0b26f01079fe4da",
            "95da796ec2f04398ba85acf0bb549953",
            "7d1883b8cea64ec5ac0b6009d4348f2e",
            "17fca6fc1bb343d697923a748027334c",
            "2f79615a0ea24bce9f99fd7b47d8d60e",
            "d32e4fb1431349cd911a000fa07c3a0f",
            "019698f3535b4e69bf7550919919f047",
            "6669128ad00540afa7c31822687e6e74",
            "e776195ebdee427898db105e1cacb78f",
            "f3ee79c4994248069e14d4069b61eaff",
            "ec93a8b903784bc9ab3174aae4a7f6a7",
            "711168eadc0d454989fa3929d75e7b3a",
            "52ca316900c648129ff2aa44020eff71",
            "c41e8244462d4882990e37eef5e5e2b7",
            "4f41383c47cd494b847bc0bcda831c76",
            "8b52b86208114a27b12984dd600665b2",
            "ef789fb211ee44b09fc7d02607e7acba",
            "b976fcd40b84431f8bbb360168001707",
            "3414cdb719e14617914babc8283fa2b1",
            "871c69ab0a47497481f0f6b4c5f1e51b",
            "8f9a02324adf4860938bb4ae4279c026",
            "b51dab3d2e0c4f4b81272a8cef4d08a8",
            "24a7714523984fecb0f00588222ef10d",
            "136a1488197b4414819d638364aad7e7",
            "7793ac75620e444299ab766be23a387c",
            "d950d691a23f47269be39e142822d1df",
            "ea02688fe2044a288e50bd7da1099e45",
            "62b1845c26f847d8bbf00099eed85d10",
            "582b00fc6ad24989892ee45725397e33",
            "b551fe2978d94c0a8610ee0be64061ee",
            "f01c13ac88cc4d2aae1255e43089bb0e",
            "79eba3f766a7412280aaa5a63fc6074a",
            "7637027db71d441893d1a013c9f27595",
            "b0fbb9b594024f2899d4d38809b7b7c6",
            "49f14d60103b4d92b3717e714b98d596",
            "6c39c39b339c492f86a0b408c296ab7f",
            "f2129644277d4cbba52e1cc7a83401a0",
            "2b6ad276be7b4b49bba679bcc8531831",
            "d6aae1151bf14bf980e7e9c211115130",
            "8462eabaf3c2462cb90df2981fef9630",
            "baed451eeb804bfa981a0b6487123650",
            "a0552cb106b9463db289cdaa29395ea4",
            "92f98aedeb73425c9d8f7f2c2ddc5631",
            "60f3f0bbc73c47b9bf7b8d130af0e459",
            "ad5d6a3ecffb432d92530bd73f99edb7",
            "aed64d37cff2444eb26deb97e2c50ca6",
            "d4f8d78e52854cc2bc1057bca2ff097c",
            "5e0f8d3b64ca4bd48c80f193c4e6bbe7",
            "c30766d3199442d5b059cc4b076a1a52",
            "7e91a256e2fe4aafa844158e0a5cdcb7",
            "99cc3eb31c8e4b65bf7cb4235caa6027",
            "6806dd14628045bb8b31f82cc9b6e20c",
            "f2c9ec43929248ee86808394866a6882",
            "7c14aacf4a8041d398a5de792f3da991",
            "e0466d7b846d40349605628ff2a51824",
            "ffce7a32cd534598b13579297172c69f",
            "9d83763a5a7b4759939d436fec9e43a4",
            "f0586ed92beb4970a05ff90ecdec32bd",
            "765f90aec0224991b5a03581c4aff5ea",
            "59235e25bc0f4d3ba444b7a9488fad61",
            "286df3016b65495a8a86b12904fe7c91",
            "511d0f3e4c614768a3e25d70a9599af5",
            "eda9fd72761340daaa8be9134bad76cf",
            "9a277bbd8eda42e1a4cd781ac2742fa3",
            "af31c4416ac244fea34d20e283513956",
            "e7ba838ab7cc41e6a6be17cfeb873cb0",
            "b9f112e4472648a39b2324bf6e5059fc",
            "1fba7f0395144a0d8e3abba3a9f6e00f",
            "87b34d0caf904fc893d13379fe8fdb55",
            "580173caae6f4a619240d657737233d6",
            "61af7612809f47b58d5b10c88bf34304",
            "786cb13089c640e4806ee708066504bb",
            "fe8c2408f4e6493fbc65ef258fe8b555",
            "5dc36a91dd3c45e1ba261638b65a0f96",
            "22f629dde72e461c9bb8297f31a9d8d0",
            "4a80df9c96ae4a4381a71ffa54959ea6",
            "28c3dd0944d547f1a7f6c6b8e7c81e87",
            "5e806e0607bf45d4a17b2f145e12b748",
            "867990cb845846ee9c9a35e1ba5c649e",
            "a6f0bf8b9ba446c7b238b547bfd0dc9d",
            "d9181ea271a5402bae6e985b45c8877b",
            "f3f349a18dc940dbb7cbd52369341bd5",
            "e6111ba6004f44b899c12a670644dc77",
            "a4b50800f07b4377b7ef2688c60b3f9a",
            "731e2a9cbc2649ce89f7d8cdc8cbdfb0",
            "c0c9f3dbb10e4988ad4a493b4ebf0cd1",
            "679863fcc37e4782b2075e1de00a825d",
            "764fdb2534b645da9a486cb486e0bc92",
            "e6e221e6d03249e8bca58647f18b187c",
            "62e63a3a7b074f5595a2c1629e3a078f",
            "74c9616636004a8880318b07347d8b40",
            "2032a01b762d4276ba96eaeda905ddb4",
            "65df71d5917c46bb84ea27fab0be08cc",
            "0a7139506eaf45d4a97640db205bc159",
            "66118c021b8a4458b38588f7f0be5fce",
            "ded6c729c4c84f34a168b48dccfe0f03",
            "b499faaef9984a418ba86fec2692ebea",
            "e853f996bc8a42e78eff493eb736f7c4",
            "90c6460d63804da9b9d2831a6426424a",
            "ef6498679236472e807ff4bcc56214e7",
            "6897f4e661ab43f3a046ee5b6b2e2641",
            "412ca3359f4b4fc2bcb612d44f4d7e25",
            "f45313470ca6497c92c9eeb004c83ec5",
            "6cfd1df101014a5e9dbe5d99806f5906",
            "08970cdf1f374b9289deee606cca0fac",
            "9b920ddfb6524ae59c7f35679acc829a",
            "60938fda0d3c4c49a454ffae9dd0712d",
            "d17adfca6bb4429eb98b054eaa26884e",
            "abfff29619dd43a29001669186aa0f11",
            "795285a7956541be9deaed4a5f16f709"
          ]
        },
        "id": "JG0DPozntEhy",
        "outputId": "bf14894c-92a3-4cfb-e0bb-7b9ff0cd1053"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Setting Up Multi-Agent CRM System\n",
            "======================================================================\n",
            "\n",
            "[Sales Rep] Loading Qwen2.5-0.5B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:06.985\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.986\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptj'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.986\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-j'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.987\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'codellama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'pythia'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.990\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-neox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptneox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mistral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mixtral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.994\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.994\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'bert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.996\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'roberta'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'distilbert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5-base'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mt5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'generic'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:06.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'unknown'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:07.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36m_register_default_binders\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mRegistered 25 default binders\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:07.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mInitialized UAL for qwen model with 494,032,768 parameters\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mInitialized LoRA Dispatcher with encoder: all-MiniLM-L6-v2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.076\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> transformer.h.0.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> transformer.h.0.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> transformer.h.1.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.078\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> transformer.h.1.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.079\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> transformer.h.10.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.079\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> transformer.h.10.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.080\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> transformer.h.11.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.080\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> transformer.h.11.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> transformer.h.2.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> transformer.h.2.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> transformer.h.3.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> transformer.h.3.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> transformer.h.4.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> transformer.h.4.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.085\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> transformer.h.5.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.085\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> transformer.h.5.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.086\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> transformer.h.6.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> transformer.h.6.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> transformer.h.7.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> transformer.h.7.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> transformer.h.8.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> transformer.h.8.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> transformer.h.9.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> transformer.h.9.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 896\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'negotiation' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'negotiation'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Registering skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9465a9e5ddaa4b3fb751efdedc93117d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:08.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'negotiation' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.381\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> transformer.h.0.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.382\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> transformer.h.0.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.383\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> transformer.h.1.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.383\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> transformer.h.1.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.384\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> transformer.h.10.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.385\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> transformer.h.10.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.385\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> transformer.h.11.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.386\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> transformer.h.11.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.386\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> transformer.h.2.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.387\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> transformer.h.2.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.388\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> transformer.h.3.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.388\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> transformer.h.3.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.389\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> transformer.h.4.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.389\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> transformer.h.4.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.390\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> transformer.h.5.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.390\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> transformer.h.5.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> transformer.h.6.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> transformer.h.6.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.392\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> transformer.h.7.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> transformer.h.7.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> transformer.h.8.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.394\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> transformer.h.8.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.395\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> transformer.h.9.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.395\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> transformer.h.9.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 896\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'communication' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'communication'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ negotiation\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aab3584101de46138c2d32dc74691de5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:08.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'communication' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.437\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> transformer.h.0.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.437\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> transformer.h.0.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.438\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> transformer.h.1.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.439\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> transformer.h.1.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.439\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> transformer.h.10.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.440\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> transformer.h.10.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.440\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> transformer.h.11.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.442\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> transformer.h.11.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.443\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> transformer.h.2.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.443\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> transformer.h.2.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.443\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> transformer.h.3.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> transformer.h.3.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.445\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> transformer.h.4.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.445\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> transformer.h.4.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.446\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> transformer.h.5.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.447\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> transformer.h.5.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.447\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> transformer.h.6.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.449\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> transformer.h.6.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.449\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> transformer.h.7.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> transformer.h.7.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> transformer.h.8.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.451\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> transformer.h.8.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.451\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> transformer.h.9.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.452\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> transformer.h.9.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 896\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'product_knowledge' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'product_knowledge'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ communication\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c36d0a05f1944155b0b26f01079fe4da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:08.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'product_knowledge' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:08.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ product_knowledge\n",
            "\n",
            "[Support Specialist] Loading TinyLlama-1.1B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:09.771\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.772\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptj'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.772\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-j'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.773\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.773\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.774\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.774\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'codellama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.774\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'pythia'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.775\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-neox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.776\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptneox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.776\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.776\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.777\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mistral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.777\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mixtral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.778\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.779\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.779\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.780\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'bert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.780\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'roberta'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.781\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'distilbert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.781\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.782\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5-base'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.783\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mt5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.783\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'generic'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.783\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'unknown'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36m_register_default_binders\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mRegistered 25 default binders\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:09.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mInitialized UAL for llama model with 1,100,048,384 parameters\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mInitialized LoRA Dispatcher with encoder: all-MiniLM-L6-v2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.852\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> model.layers.0.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> model.layers.0.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> model.layers.1.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.854\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> model.layers.1.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.855\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> model.layers.10.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.855\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> model.layers.10.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.856\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> model.layers.11.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.856\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> model.layers.11.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.856\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> model.layers.2.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.857\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> model.layers.2.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> model.layers.3.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> model.layers.3.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> model.layers.4.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.859\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> model.layers.4.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.860\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> model.layers.5.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.860\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> model.layers.5.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> model.layers.6.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> model.layers.6.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.862\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> model.layers.7.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.862\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> model.layers.7.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> model.layers.8.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> model.layers.8.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.864\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> model.layers.9.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.864\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> model.layers.9.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 2048\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'communication' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'communication'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Registering skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "711168eadc0d454989fa3929d75e7b3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:10.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'communication' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.902\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> model.layers.0.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.903\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> model.layers.0.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.903\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> model.layers.1.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.904\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> model.layers.1.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.904\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> model.layers.10.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.905\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> model.layers.10.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.906\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> model.layers.11.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.906\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> model.layers.11.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.907\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> model.layers.2.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.907\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> model.layers.2.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.908\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> model.layers.3.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.908\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> model.layers.3.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> model.layers.4.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> model.layers.4.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> model.layers.5.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> model.layers.5.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> model.layers.6.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> model.layers.6.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.912\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> model.layers.7.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> model.layers.7.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> model.layers.8.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.915\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> model.layers.8.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.915\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> model.layers.9.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.916\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> model.layers.9.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 2048\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'product_knowledge' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'product_knowledge'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ communication\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24a7714523984fecb0f00588222ef10d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:10.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'product_knowledge' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.954\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> model.layers.0.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.955\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> model.layers.0.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.955\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> model.layers.1.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.956\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> model.layers.1.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.956\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> model.layers.10.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.957\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> model.layers.10.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.957\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> model.layers.11.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.958\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> model.layers.11.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.958\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> model.layers.2.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.960\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> model.layers.2.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.960\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> model.layers.3.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.961\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> model.layers.3.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.961\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> model.layers.4.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.962\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> model.layers.4.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.963\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> model.layers.5.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.964\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> model.layers.5.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.964\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> model.layers.6.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.965\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> model.layers.6.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.965\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> model.layers.7.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.966\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> model.layers.7.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.966\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> model.layers.8.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.967\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> model.layers.8.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.967\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> model.layers.9.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> model.layers.9.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 2048\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'compliance' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:10.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'compliance'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ product_knowledge\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0fbb9b594024f2899d4d38809b7b7c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'compliance' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ compliance\n",
            "\n",
            "[Account Manager] Loading SmolLM2-360M...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:11.932\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.932\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptj'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.933\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-j'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.933\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.934\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.934\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.935\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'codellama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.935\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'pythia'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.936\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-neox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.936\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptneox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.937\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.937\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.938\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mistral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.939\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mixtral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.939\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.940\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.940\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.941\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'bert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'roberta'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'distilbert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.943\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.943\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5-base'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.944\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mt5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.944\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'generic'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.945\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'unknown'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36m_register_default_binders\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mRegistered 25 default binders\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:11.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mInitialized UAL for llama model with 361,821,120 parameters\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mInitialized LoRA Dispatcher with encoder: all-MiniLM-L6-v2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.154\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> model.layers.0.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> model.layers.0.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> model.layers.1.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> model.layers.1.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.156\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> model.layers.10.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.157\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> model.layers.10.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.157\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> model.layers.11.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.158\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> model.layers.11.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.158\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> model.layers.2.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.159\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> model.layers.2.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.159\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> model.layers.3.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.160\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> model.layers.3.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> model.layers.4.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> model.layers.4.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> model.layers.5.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> model.layers.5.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.163\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> model.layers.6.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.163\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> model.layers.6.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.164\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> model.layers.7.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.164\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> model.layers.7.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> model.layers.8.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> model.layers.8.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.166\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> model.layers.9.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> model.layers.9.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 960\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'crm_mastery' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'crm_mastery'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Registering skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad5d6a3ecffb432d92530bd73f99edb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:13.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'crm_mastery' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.199\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> model.layers.0.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.200\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> model.layers.0.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.200\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> model.layers.1.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.201\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> model.layers.1.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.201\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> model.layers.10.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.202\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> model.layers.10.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.202\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> model.layers.11.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.203\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> model.layers.11.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.203\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> model.layers.2.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.204\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> model.layers.2.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.204\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> model.layers.3.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.205\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> model.layers.3.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.205\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> model.layers.4.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.206\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> model.layers.4.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.206\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> model.layers.5.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.207\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> model.layers.5.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.209\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> model.layers.6.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.209\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> model.layers.6.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.210\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> model.layers.7.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.211\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> model.layers.7.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.211\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> model.layers.8.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> model.layers.8.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.213\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> model.layers.9.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.213\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> model.layers.9.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 960\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'communication' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'communication'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ crm_mastery\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffce7a32cd534598b13579297172c69f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:13.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'communication' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.249\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> model.layers.0.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.249\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> model.layers.0.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.250\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> model.layers.1.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.250\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> model.layers.1.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.251\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> model.layers.10.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.252\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> model.layers.10.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.252\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> model.layers.11.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> model.layers.11.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> model.layers.2.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.254\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> model.layers.2.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> model.layers.3.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> model.layers.3.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> model.layers.4.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> model.layers.4.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> model.layers.5.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> model.layers.5.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.258\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> model.layers.6.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.259\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> model.layers.6.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.259\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> model.layers.7.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.260\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> model.layers.7.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.260\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> model.layers.8.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.261\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> model.layers.8.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.261\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> model.layers.9.self_attn.q_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.262\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> model.layers.9.mlp.down_proj\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 960\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'data_analytics' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'data_analytics'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ communication\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f112e4472648a39b2324bf6e5059fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:13.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'data_analytics' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:13.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ data_analytics\n",
            "\n",
            "[Data Analyst] Loading Qwen2.5-1.5B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:15.268\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.268\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptj'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.269\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-j'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.269\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.270\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.270\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'llama3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.271\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'codellama'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.271\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'pythia'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gpt-neox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'gptneox'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.273\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.273\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'qwen2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.274\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mistral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.274\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mixtral'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.275\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi2'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'phi3'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'bert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'roberta'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'distilbert'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.279\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 't5-base'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.279\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'mt5'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.280\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'generic'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.280\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mRegistered binder for 'unknown'\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.binders.registry\u001b[0m:\u001b[36m_register_default_binders\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mRegistered 25 default binders\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:15.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mInitialized UAL for qwen model with 1,543,714,304 parameters\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mInitialized LoRA Dispatcher with encoder: all-MiniLM-L6-v2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.351\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> transformer.h.0.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.352\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> transformer.h.0.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.352\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> transformer.h.1.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.353\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> transformer.h.1.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.353\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> transformer.h.10.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.354\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> transformer.h.10.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.354\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> transformer.h.11.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.355\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> transformer.h.11.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.355\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> transformer.h.2.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.356\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> transformer.h.2.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.356\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> transformer.h.3.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.357\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> transformer.h.3.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.358\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> transformer.h.4.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.358\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> transformer.h.4.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> transformer.h.5.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> transformer.h.5.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.360\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> transformer.h.6.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.360\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> transformer.h.6.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.361\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> transformer.h.7.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.361\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> transformer.h.7.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.362\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> transformer.h.8.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.362\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> transformer.h.8.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> transformer.h.9.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> transformer.h.9.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 1536\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'data_analytics' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'data_analytics'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Registering skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e806e0607bf45d4a17b2f145e12b748"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:16.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'data_analytics' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.394\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> transformer.h.0.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.394\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> transformer.h.0.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.395\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> transformer.h.1.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.395\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> transformer.h.1.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> transformer.h.10.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> transformer.h.10.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> transformer.h.11.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.397\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> transformer.h.11.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> transformer.h.2.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> transformer.h.2.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> transformer.h.3.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> transformer.h.3.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.400\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> transformer.h.4.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.400\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> transformer.h.4.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.401\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> transformer.h.5.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.401\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> transformer.h.5.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> transformer.h.6.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> transformer.h.6.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> transformer.h.7.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> transformer.h.7.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> transformer.h.8.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> transformer.h.8.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.405\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> transformer.h.9.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.405\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> transformer.h.9.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 1536\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'crm_mastery' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'crm_mastery'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ data_analytics\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e221e6d03249e8bca58647f18b187c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:16.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'crm_mastery' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.attention_query -> transformer.h.0.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.445\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_0.mlp_down -> transformer.h.0.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.445\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.attention_query -> transformer.h.1.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.446\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_1.mlp_down -> transformer.h.1.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.446\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.attention_query -> transformer.h.10.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.447\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_10.mlp_down -> transformer.h.10.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.447\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.attention_query -> transformer.h.11.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.448\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_11.mlp_down -> transformer.h.11.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.448\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.attention_query -> transformer.h.2.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.449\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_2.mlp_down -> transformer.h.2.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.449\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.attention_query -> transformer.h.3.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_3.mlp_down -> transformer.h.3.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.attention_query -> transformer.h.4.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.451\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_4.mlp_down -> transformer.h.4.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.451\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.attention_query -> transformer.h.5.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.453\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_5.mlp_down -> transformer.h.5.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.454\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.attention_query -> transformer.h.6.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.455\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_6.mlp_down -> transformer.h.6.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.456\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.attention_query -> transformer.h.7.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.456\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_7.mlp_down -> transformer.h.7.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.457\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.attention_query -> transformer.h.8.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.458\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_8.mlp_down -> transformer.h.8.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.458\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.attention_query -> transformer.h.9.attn.c_attn\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.459\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mMapped layer_9.mlp_down -> transformer.h.9.mlp.w2\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.air\u001b[0m:\u001b[36mimport_from_air\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mImported 24 weights from AIR format\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProjecting dimensions: 768 -> 1536\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.adapter\u001b[0m:\u001b[36mimport_adapter\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mâœ… Imported adapter 'compliance' (0.0% attachment rate)\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComputing embeddings for domain 'compliance'...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ crm_mastery\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef6498679236472e807ff4bcc56214e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-02 15:19:16.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36mregister_domain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mRegistered domain 'compliance' with 5 training samples\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining router classifier...\u001b[0m\n",
            "\u001b[32m2025-11-02 15:19:16.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mual_adapter.core.dispatcher\u001b[0m:\u001b[36m_train_router\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mRouter accuracy on training data: 100.00%\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    âœ“ compliance\n",
            "\n",
            "======================================================================\n",
            "âœ… All 4 agents configured and ready!\n",
            "======================================================================\n",
            "\n",
            "Agent Summary:\n",
            "  â€¢ Sales Rep: Qwen2.5-0.5B with 3 skills\n",
            "  â€¢ Support Specialist: TinyLlama-1.1B with 3 skills\n",
            "  â€¢ Account Manager: SmolLM2-360M with 3 skills\n",
            "  â€¢ Data Analyst: Qwen2.5-1.5B with 3 skills\n",
            "\n",
            "âœ… Each agent has:\n",
            "   â€¢ Base model loaded\n",
            "   â€¢ UAL adapter configured\n",
            "   â€¢ Intelligent dispatcher ready\n",
            "   â€¢ Skills dynamically available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# Alternative Code- compact code\n",
        "# ==================================================\n",
        "# \"\"\"\n",
        "\n",
        "# import torch\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# from ual_adapter import UniversalAdapter\n",
        "# from ual_adapter.core.dispatcher import LoRADispatcher\n",
        "\n",
        "# # Agent configurations with model assignments\n",
        "# agent_configs = {\n",
        "#     'sales_rep': {\n",
        "#         'model_name': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
        "#         'skills': ['negotiation', 'communication', 'product_knowledge']\n",
        "#     },\n",
        "#     'support_specialist': {\n",
        "#         'model_name': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "#         'skills': ['communication', 'product_knowledge', 'compliance']\n",
        "#     },\n",
        "#     'account_manager': {\n",
        "#         'model_name': 'HuggingFaceTB/SmolLM2-360M-Instruct',\n",
        "#         'skills': ['crm_mastery', 'communication', 'data_analytics']\n",
        "#     },\n",
        "#     'data_analyst': {\n",
        "#         'model_name': 'Qwen/Qwen2.5-1.5B-Instruct',\n",
        "#         'skills': ['data_analytics', 'crm_mastery', 'compliance']\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# print('='*70)\n",
        "# print('Configuring Backend Models with Dispatchers')\n",
        "# print('='*70)\n",
        "\n",
        "# # Initialize agents dictionary\n",
        "# agents = {}\n",
        "\n",
        "# for agent_name, config in agent_configs.items():\n",
        "#     print(f'\\n[{agent_name}] Loading {config[\"model_name\"]}...')\n",
        "\n",
        "#     # Load model and tokenizer\n",
        "#     model = AutoModelForCausalLM.from_pretrained(\n",
        "#         config['model_name'],\n",
        "#         torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "#         device_map='auto' if torch.cuda.is_available() else None,\n",
        "#         low_cpu_mem_usage=True\n",
        "#     )\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
        "#     if tokenizer.pad_token is None:\n",
        "#         tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#     # Create UAL adapter for this model\n",
        "#     # FIXED: Changed 'model' to 'base_model' and removed 'model_name'\n",
        "#     ual_adapter = UniversalAdapter(\n",
        "#         base_model=model,\n",
        "#         tokenizer=tokenizer,\n",
        "#         device='auto'\n",
        "#     )\n",
        "\n",
        "#     # Create dispatcher with LOWER threshold\n",
        "#     dispatcher = LoRADispatcher(\n",
        "#         encoder_model='all-MiniLM-L6-v2',\n",
        "#         confidence_threshold=0.30  # Lower threshold for better matching\n",
        "#     )\n",
        "\n",
        "#     # Register each skill for this agent\n",
        "#     print(f'  Registering skills:')\n",
        "#     for skill_name in config['skills']:\n",
        "#         air_path = f'skills/{skill_name}.air'\n",
        "\n",
        "#         # Import AIR file\n",
        "#         ual_adapter.import_adapter(air_path)\n",
        "\n",
        "#         # Get adapter weights\n",
        "#         adapter_weights = ual_adapter.adapters[skill_name]\n",
        "\n",
        "#         # Get training data for this skill\n",
        "#         training_data = skills[skill_name]\n",
        "\n",
        "#         # Register with dispatcher\n",
        "#         dispatcher.register_domain(\n",
        "#             domain_name=skill_name,\n",
        "#             adapter_weights=adapter_weights,\n",
        "#             training_texts=training_data\n",
        "#         )\n",
        "\n",
        "#         print(f'    âœ“ {skill_name}')\n",
        "\n",
        "#     # Store agent configuration\n",
        "#     agents[agent_name] = {\n",
        "#         'config': config,\n",
        "#         'model': model,\n",
        "#         'tokenizer': tokenizer,\n",
        "#         'ual': ual_adapter,\n",
        "#         'dispatcher': dispatcher\n",
        "#     }\n",
        "\n",
        "# print('\\n' + '='*70)\n",
        "# print('âœ… All agents configured!')\n",
        "# print('='*70)\n",
        "\n",
        "# # Display configuration\n",
        "# print('\\nAgent Configuration Summary:')\n",
        "# for agent_name, agent_data in agents.items():\n",
        "#     print(f'\\n  {agent_name}:')\n",
        "#     print(f'    Model: {agent_data[\"config\"][\"model_name\"].split(\"/\")[-1]}')\n",
        "#     print(f'    Skills: {\", \".join(agent_data[\"config\"][\"skills\"])}')\n",
        "#     print(f'    Dispatcher ready: âœ“')\n",
        "\n",
        "# print('\\nâœ… Each agent now has:')\n",
        "# print('   â€¢ Backend model loaded')\n",
        "# print('   â€¢ UAL adapter configured')\n",
        "# print('   â€¢ Dispatcher with registered skills')\n",
        "# print('   â€¢ Access to AIR files for dynamic loading')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U3XdxbGkhvUk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ­ Google ADK Multi-Agent Orchestra - Putting It All Together\n",
        "\n",
        "### ğŸ¯ **What This Cell Does**\n",
        "This is the **grand finale**! This cell:\n",
        "1. Creates tool functions that connect Google ADK to your backend models\n",
        "2. Builds 4 specialist agents (one for each role)\n",
        "3. Creates a Planner agent that orchestrates everything\n",
        "4. Establishes the complete multi-agent system\n",
        "\n",
        "### ğŸ—ï¸ **Architecture**\n",
        "\n",
        "```\n",
        "    Customer Query\n",
        "          â†“\n",
        "    [Gemini Planner]\n",
        "          â†“\n",
        "    Analyzes & Routes\n",
        "          â†“\n",
        "     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”\n",
        "     â†“         â†“    â†“    â†“\n",
        "  Sales   Support Acct Data\n",
        "   Rep     Spec   Mgr  Analyst\n",
        "   â†“         â†“      â†“    â†“\n",
        " Qwen   TinyLlama SmolLM Qwen\n",
        " 0.5B     1.1B    360M  1.5B\n",
        "   â†“         â†“      â†“    â†“\n",
        "Dispatcher Dispatcher Dispatcher\n",
        "   â†“         â†“      â†“    â†“\n",
        "Skills   Skills  Skills Skills\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”§ **The 3 Layers**\n",
        "\n",
        "**Layer 1: Tool Functions** - Connect ADK to backend models\n",
        "**Layer 2: Specialist Agents** - Each with specific role\n",
        "**Layer 3: Planner Agent** - Orchestrates everything\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **How It Works**\n",
        "\n",
        "1. Customer asks a question\n",
        "2. Planner analyzes and routes to best agent\n",
        "3. Agent calls its tool function\n",
        "4. Tool uses backend model + dispatcher\n",
        "5. Dispatcher selects best skill\n",
        "6. Result flows back to customer\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  **Key Innovation**\n",
        "\n",
        "**Hybrid Architecture:**\n",
        "- Gemini for smart reasoning & routing\n",
        "- Local models for specialized knowledge\n",
        "- Best of both worlds!\n",
        "\n",
        "---\n",
        "\n",
        "### â±ï¸ **Expected Time**\n",
        "**~30 seconds**\n",
        "\n",
        "### âœ… **Success Indicators**\n",
        "```\n",
        "âœ… Gemini API key found\n",
        "âœ… Tool functions created\n",
        "âœ… ADK Multi-Agent System Created!"
      ],
      "metadata": {
        "id": "JX42xF7MvCET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from typing import Dict\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.tools import FunctionTool\n",
        "from google.adk.runners import InMemoryRunner\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - [%(name)s] - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger('CRM_System')\n",
        "\n",
        "# Check Gemini API key\n",
        "GEMINI_AVAILABLE = 'GOOGLE_API_KEY' in os.environ or 'GEMINI_API_KEY' in os.environ\n",
        "\n",
        "if GEMINI_AVAILABLE:\n",
        "    print('âœ… Gemini API key found')\n",
        "    GEMINI_MODEL = \"gemini-2.0-flash-exp\"\n",
        "else:\n",
        "    print('âš ï¸  No Gemini API key found')\n",
        "    print('   Set GOOGLE_API_KEY environment variable')\n",
        "    GEMINI_MODEL = \"gemini-1.5-flash\"\n",
        "\n",
        "print(f'   Using model: {GEMINI_MODEL}\\n')\n",
        "\n",
        "# =============================================================================\n",
        "# Tool Functions - Connect ADK to Backend Models + Dispatchers\n",
        "# =============================================================================\n",
        "\n",
        "def sales_tool(query: str) -> Dict[str, str]:\n",
        "    \"\"\"Sales Rep tool - uses Qwen 0.5B backend with dispatcher\"\"\"\n",
        "\n",
        "    agent_data = agents['sales_rep']\n",
        "    dispatcher = agent_data['dispatcher']\n",
        "    model_name = agent_data['config']['model_name']\n",
        "\n",
        "    # Dispatcher selects best skill\n",
        "    skill_name, confidence, all_scores = dispatcher.route_query(\n",
        "        query,\n",
        "        return_all_scores=True\n",
        "    )\n",
        "\n",
        "    logger.info(f\"[Sales Rep] Query: {query[:50]}...\")\n",
        "    logger.info(f\"[Sales Rep] Selected skill: {skill_name} ({confidence:.1%} confidence)\")\n",
        "\n",
        "    # In production, you would:\n",
        "    # 1. Load the skill adapter if not already loaded\n",
        "    # 2. Run inference with the model\n",
        "    # For demo, return selection info\n",
        "\n",
        "    return {\n",
        "        'agent': 'Sales Rep',\n",
        "        'model': model_name.split('/')[-1],\n",
        "        'skill_selected': skill_name or 'base',\n",
        "        'confidence': f\"{confidence:.1%}\",\n",
        "        'all_skills_available': list(all_scores.keys()),\n",
        "        'result': f\"Processed with {skill_name} skill on {model_name.split('/')[-1]}\" if skill_name else \"Using base model\"\n",
        "    }\n",
        "\n",
        "\n",
        "def support_tool(query: str) -> Dict[str, str]:\n",
        "    \"\"\"Support Specialist tool - uses TinyLlama 1.1B backend with dispatcher\"\"\"\n",
        "\n",
        "    agent_data = agents['support_specialist']\n",
        "    dispatcher = agent_data['dispatcher']\n",
        "    model_name = agent_data['config']['model_name']\n",
        "\n",
        "    skill_name, confidence, all_scores = dispatcher.route_query(\n",
        "        query,\n",
        "        return_all_scores=True\n",
        "    )\n",
        "\n",
        "    logger.info(f\"[Support] Query: {query[:50]}...\")\n",
        "    logger.info(f\"[Support] Selected skill: {skill_name} ({confidence:.1%} confidence)\")\n",
        "\n",
        "    return {\n",
        "        'agent': 'Support Specialist',\n",
        "        'model': model_name.split('/')[-1],\n",
        "        'skill_selected': skill_name or 'base',\n",
        "        'confidence': f\"{confidence:.1%}\",\n",
        "        'all_skills_available': list(all_scores.keys()),\n",
        "        'result': f\"Processed with {skill_name} skill on {model_name.split('/')[-1]}\" if skill_name else \"Using base model\"\n",
        "    }\n",
        "\n",
        "\n",
        "def account_tool(query: str) -> Dict[str, str]:\n",
        "    \"\"\"Account Manager tool - uses SmolLM 360M backend with dispatcher\"\"\"\n",
        "\n",
        "    agent_data = agents['account_manager']\n",
        "    dispatcher = agent_data['dispatcher']\n",
        "    model_name = agent_data['config']['model_name']\n",
        "\n",
        "    skill_name, confidence, all_scores = dispatcher.route_query(\n",
        "        query,\n",
        "        return_all_scores=True\n",
        "    )\n",
        "\n",
        "    logger.info(f\"[Account Mgr] Query: {query[:50]}...\")\n",
        "    logger.info(f\"[Account Mgr] Selected skill: {skill_name} ({confidence:.1%} confidence)\")\n",
        "\n",
        "    return {\n",
        "        'agent': 'Account Manager',\n",
        "        'model': model_name.split('/')[-1],\n",
        "        'skill_selected': skill_name or 'base',\n",
        "        'confidence': f\"{confidence:.1%}\",\n",
        "        'all_skills_available': list(all_scores.keys()),\n",
        "        'result': f\"Processed with {skill_name} skill on {model_name.split('/')[-1]}\" if skill_name else \"Using base model\"\n",
        "    }\n",
        "\n",
        "\n",
        "def analyst_tool(query: str) -> Dict[str, str]:\n",
        "    \"\"\"Data Analyst tool - uses Qwen 1.5B backend with dispatcher\"\"\"\n",
        "\n",
        "    agent_data = agents['data_analyst']\n",
        "    dispatcher = agent_data['dispatcher']\n",
        "    model_name = agent_data['config']['model_name']\n",
        "\n",
        "    skill_name, confidence, all_scores = dispatcher.route_query(\n",
        "        query,\n",
        "        return_all_scores=True\n",
        "    )\n",
        "\n",
        "    logger.info(f\"[Data Analyst] Query: {query[:50]}...\")\n",
        "    logger.info(f\"[Data Analyst] Selected skill: {skill_name} ({confidence:.1%} confidence)\")\n",
        "\n",
        "    return {\n",
        "        'agent': 'Data Analyst',\n",
        "        'model': model_name.split('/')[-1],\n",
        "        'skill_selected': skill_name or 'base',\n",
        "        'confidence': f\"{confidence:.1%}\",\n",
        "        'all_skills_available': list(all_scores.keys()),\n",
        "        'result': f\"Processed with {skill_name} skill on {model_name.split('/')[-1]}\" if skill_name else \"Using base model\"\n",
        "    }\n",
        "\n",
        "\n",
        "print('âœ… Tool functions created\\n')\n",
        "\n",
        "# =============================================================================\n",
        "# Create ADK Agents\n",
        "# =============================================================================\n",
        "\n",
        "print('Creating ADK agents...\\n')\n",
        "\n",
        "# Sub-agents\n",
        "sales_agent = Agent(\n",
        "    name=\"sales_rep\",\n",
        "    model=GEMINI_MODEL,\n",
        "    description=\"Sales Representative with Qwen 0.5B backend. Skills: negotiation, communication, product_knowledge\",\n",
        "    instruction=\"\"\"You are an enterprise sales representative with specialized LoRA skills.\n",
        "\n",
        "    Backend Model: Qwen 0.5B with UAL dynamic skill loading\n",
        "    Available Skills: negotiation, communication, product_knowledge\n",
        "\n",
        "    ğŸš¨ CRITICAL - YOU MUST FOLLOW THIS EXACT PROCESS:\n",
        "\n",
        "    STEP 1 - CALL THE TOOL (ABSOLUTELY MANDATORY):\n",
        "    You MUST immediately call: sales_tool(query=\"<user's exact query>\")\n",
        "\n",
        "    DO NOT:\n",
        "    âŒ Answer without calling the tool\n",
        "    âŒ Skip calling the tool\n",
        "    âŒ Try to respond directly\n",
        "    âŒ NEVER mention to users:\n",
        "      - \"confidence of X%\"\n",
        "      - \"my analysis points to ...\"\n",
        "      - \"using negotiation skill\"\n",
        "\n",
        "    The sales_tool function will:\n",
        "    - Analyze the query semantically\n",
        "    - Select the best LoRA skill (negotiation, communication, or product_knowledge)\n",
        "    - Return skill selection with confidence score\n",
        "\n",
        "    STEP 2 - RESPOND (ONLY AFTER CALLING THE TOOL):\n",
        "    After receiving the tool's output, provide your sales response based on:\n",
        "    - The selected skill\n",
        "    - The skill confidence\n",
        "    - The tool result\n",
        "\n",
        "    REMEMBER: Your LoRA skills are ONLY accessible through the tool. You CANNOT access them any other way.\n",
        "\n",
        "    Example flow:\n",
        "    User: \"Help me negotiate a deal\"\n",
        "    You: [Call sales_tool] â†’ [Get result] â†’ [Provide negotiation advice using tool output]\n",
        "\n",
        "    EVERY response MUST start by calling sales_tool first.\"\"\",\n",
        "        tools=[FunctionTool(sales_tool)]\n",
        "    )\n",
        "\n",
        "support_agent = Agent(\n",
        "    name=\"support_specialist\",\n",
        "    model=GEMINI_MODEL,\n",
        "    description=\"Support Specialist with TinyLlama 1.1B backend. Skills: communication, product_knowledge, compliance\",\n",
        "    instruction=\"\"\"You are a customer support specialist with specialized LoRA skills.\n",
        "\n",
        "    Backend Model: TinyLlama 1.1B with UAL dynamic skill loading\n",
        "    Available Skills: communication, product_knowledge, compliance\n",
        "\n",
        "    ğŸš¨ CRITICAL - YOU MUST FOLLOW THIS EXACT PROCESS:\n",
        "\n",
        "    STEP 1 - CALL THE TOOL (ABSOLUTELY MANDATORY):\n",
        "    You MUST immediately call: support_tool(query=\"<user's exact query>\")\n",
        "\n",
        "    DO NOT:\n",
        "    âŒ Answer without calling the tool\n",
        "    âŒ Skip calling the tool\n",
        "    âŒ Try to respond directly\n",
        "    âŒ NEVER mention to users:\n",
        "      - \"confidence of X%\"\n",
        "      - \"my analysis points to ...\"\n",
        "      - \"using negotiation skill\"\n",
        "\n",
        "    The support_tool function will:\n",
        "    - Analyze the query semantically\n",
        "    - Select the best LoRA skill (communication, product_knowledge, or compliance)\n",
        "    - Return skill selection with confidence score\n",
        "\n",
        "    STEP 2 - RESPOND (ONLY AFTER CALLING THE TOOL):\n",
        "    After receiving the tool's output, provide technical support based on:\n",
        "    - The selected skill\n",
        "    - The skill confidence\n",
        "    - The tool result\n",
        "\n",
        "    REMEMBER: Your LoRA skills are ONLY accessible through the tool. You CANNOT access them any other way.\n",
        "\n",
        "    Example flow:\n",
        "    User: \"Explain GDPR compliance\"\n",
        "    You: [Call support_tool] â†’ [Get result] â†’ [Provide compliance guidance using tool output]\n",
        "\n",
        "    EVERY response MUST start by calling support_tool first.\"\"\",\n",
        "        tools=[FunctionTool(support_tool)]\n",
        "    )\n",
        "\n",
        "account_agent = Agent(\n",
        "    name=\"account_manager\",\n",
        "    model=GEMINI_MODEL,\n",
        "    description=\"Account Manager with SmolLM 360M backend. Skills: crm_mastery, communication, data_analytics\",\n",
        "    instruction=\"\"\"You are a strategic account manager with specialized LoRA skills.\n",
        "\n",
        "    Backend Model: SmolLM 360M with UAL dynamic skill loading\n",
        "    Available Skills: crm_mastery, communication, data_analytics\n",
        "\n",
        "    ğŸš¨ CRITICAL - YOU MUST FOLLOW THIS EXACT PROCESS:\n",
        "\n",
        "    STEP 1 - CALL THE TOOL (ABSOLUTELY MANDATORY):\n",
        "    You MUST immediately call: account_tool(query=\"<user's exact query>\")\n",
        "\n",
        "    DO NOT:\n",
        "    âŒ Answer without calling the tool\n",
        "    âŒ Skip calling the tool\n",
        "    âŒ NEVER mention to users:\n",
        "      - \"confidence of X%\"\n",
        "      - \"my analysis points to ...\"\n",
        "      - \"using negotiation skill\"\n",
        "\n",
        "    The account_tool function will:\n",
        "    - Analyze the query semantically\n",
        "    - Select the best LoRA skill (crm_mastery, communication, or data_analytics)\n",
        "    - Return skill selection with confidence score\n",
        "\n",
        "    STEP 2 - RESPOND (ONLY AFTER CALLING THE TOOL):\n",
        "    After receiving the tool's output, provide strategic guidance based on:\n",
        "    - The selected skill\n",
        "    - The skill confidence\n",
        "    - The tool result\n",
        "\n",
        "    REMEMBER: Your LoRA skills are ONLY accessible through the tool. You CANNOT access them any other way.\n",
        "\n",
        "    Example flow:\n",
        "    User: \"Help with account renewal strategy\"\n",
        "    You: [Call account_tool] â†’ [Get result] â†’ [Provide CRM guidance using tool output]\n",
        "\n",
        "    EVERY response MUST start by calling account_tool first.\"\"\",\n",
        "        tools=[FunctionTool(account_tool)]\n",
        "    )\n",
        "\n",
        "analyst_agent = Agent(\n",
        "    name=\"data_analyst\",\n",
        "    model=GEMINI_MODEL,\n",
        "    description=\"Data Analyst with Qwen 1.5B backend. Skills: data_analytics, crm_mastery, compliance\",\n",
        "    instruction=\"\"\"You are a CRM data analyst with specialized LoRA skills.\n",
        "\n",
        "    Backend Model: Qwen 1.5B with UAL dynamic skill loading\n",
        "    Available Skills: data_analytics, crm_mastery, compliance\n",
        "\n",
        "    ğŸš¨ CRITICAL - YOU MUST FOLLOW THIS EXACT PROCESS:\n",
        "\n",
        "    STEP 1 - CALL THE TOOL (ABSOLUTELY MANDATORY):\n",
        "    You MUST immediately call: analyst_tool(query=\"<user's exact query>\")\n",
        "\n",
        "    DO NOT:\n",
        "    âŒ Answer without calling the tool\n",
        "    âŒ Skip calling the tool\n",
        "    âŒ Try to respond directly\n",
        "    âŒ NEVER mention to users:\n",
        "      - \"confidence of X%\"\n",
        "      - \"my analysis points to ...\"\n",
        "      - \"using negotiation skill\"\n",
        "\n",
        "    The analyst_tool function will:\n",
        "    - Analyze the query semantically\n",
        "    - Select the best LoRA skill (data_analytics, crm_mastery, or compliance)\n",
        "    - Return skill selection with confidence score\n",
        "\n",
        "    STEP 2 - RESPOND (ONLY AFTER CALLING THE TOOL):\n",
        "    After receiving the tool's output, provide data-driven insights based on:\n",
        "    - The selected skill\n",
        "    - The skill confidence\n",
        "    - The tool result\n",
        "\n",
        "    REMEMBER: Your LoRA skills are ONLY accessible through the tool. You CANNOT access them any other way.\n",
        "\n",
        "    Example flow:\n",
        "    User: \"Analyze customer churn trends\"\n",
        "    You: [Call analyst_tool] â†’ [Get result] â†’ [Provide analytics using tool output]\n",
        "\n",
        "    EVERY response MUST start by calling analyst_tool first.\"\"\",\n",
        "        tools=[FunctionTool(analyst_tool)]\n",
        "    )\n",
        "\n",
        "# Planner (root agent)\n",
        "planner = Agent(\n",
        "    name=\"crm_planner\",\n",
        "    model=GEMINI_MODEL,\n",
        "    description=\"CRM Team Planner - intelligent routing to specialist agents\",\n",
        "    instruction=\"\"\"You are the CRM Team Planner. Your ONLY job is to route queries to specialist agents.\n",
        "\n",
        "    Available Specialist Agents:\n",
        "    â€¢ sales_rep: Handles leads, demos, negotiations, pricing, sales deals\n",
        "    â€¢ support_specialist: Handles technical issues, bugs, compliance questions, GDPR\n",
        "    â€¢ account_manager: Handles renewals, relationships, strategic account planning\n",
        "    â€¢ data_analyst: Handles reports, forecasts, analytics, data insights\n",
        "\n",
        "    YOUR PROCESS FOR EVERY QUERY:\n",
        "\n",
        "    1. Read and understand the user's query\n",
        "    2. Determine which specialist agent is most appropriate\n",
        "    3. Briefly explain your routing decision (1 sentence)\n",
        "    4. IMMEDIATELY delegate to that specialist agent\n",
        "\n",
        "    CRITICAL RULES:\n",
        "    - You are ONLY a router - DO NOT answer queries yourself\n",
        "    - You do NOT have access to tools or skills - the specialists do\n",
        "    - ALWAYS delegate to a specialist - NEVER provide direct answers\n",
        "    - Use the exact agent names listed above when delegating\n",
        "    - Each specialist will use their own LoRA-adapted model and skills\n",
        "\n",
        "    Example:\n",
        "    User: \"Help me close this enterprise deal\"\n",
        "    You: \"This is a sales negotiation query. Delegating to sales_rep...\"\n",
        "    [Delegate to sales_rep]\n",
        "\n",
        "    Each specialist uses their own open-source model with dynamic UAL skill loading.\n",
        "    Your job is just intelligent routing.\"\"\",\n",
        "    sub_agents=[sales_agent, support_agent, account_agent, analyst_agent]\n",
        ")\n",
        "\n",
        "print('âœ… ADK Multi-Agent System Created!')\n",
        "print('='*70)\n",
        "print(f'Planner: {planner.name} ({GEMINI_MODEL})')\n",
        "print(f'Sub-agents: {len(planner.sub_agents)}')\n",
        "print('='*70)\n",
        "\n",
        "print('\\nArchitecture:')\n",
        "print('  Planner (Gemini Flash)')\n",
        "print('    â”œâ”€ Sales Rep (Qwen 0.5B) + dispatcher')\n",
        "print('    â”œâ”€ Support (TinyLlama 1.1B) + dispatcher')\n",
        "print('    â”œâ”€ Account Mgr (SmolLM 360M) + dispatcher')\n",
        "print('    â””â”€ Data Analyst (Qwen 1.5B) + dispatcher')\n",
        "\n",
        "print('\\nâœ… System ready for queries!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kVpymINvCbk",
        "outputId": "0a54861c-dea4-4919-9476-0061bee690f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini API key found\n",
            "   Using model: gemini-2.0-flash-exp\n",
            "\n",
            "âœ… Tool functions created\n",
            "\n",
            "Creating ADK agents...\n",
            "\n",
            "âœ… ADK Multi-Agent System Created!\n",
            "======================================================================\n",
            "Planner: crm_planner (gemini-2.0-flash-exp)\n",
            "Sub-agents: 4\n",
            "======================================================================\n",
            "\n",
            "Architecture:\n",
            "  Planner (Gemini Flash)\n",
            "    â”œâ”€ Sales Rep (Qwen 0.5B) + dispatcher\n",
            "    â”œâ”€ Support (TinyLlama 1.1B) + dispatcher\n",
            "    â”œâ”€ Account Mgr (SmolLM 360M) + dispatcher\n",
            "    â””â”€ Data Analyst (Qwen 1.5B) + dispatcher\n",
            "\n",
            "âœ… System ready for queries!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¨ Gradio Interactive Interface - Experience It Live!\n",
        "\n",
        "### ğŸ¯ **What This Cell Does**\n",
        "This is your **interactive demo**! This cell:\n",
        "1. Creates a beautiful web interface using Gradio\n",
        "2. Adds real-time activity tracking to visualize the system\n",
        "3. Implements conversation memory for context\n",
        "4. Wraps tools with logging to show what's happening\n",
        "5. Provides example queries to try\n",
        "\n",
        "### ğŸ–¥ï¸ **Interface Features**\n",
        "\n",
        "**Left Panel - Chat Interface:**\n",
        "- Type your questions naturally\n",
        "- See responses from specialist agents\n",
        "- Conversation history maintained\n",
        "- Example queries to try\n",
        "\n",
        "**Right Panel - Activity Tracker:**\n",
        "- Watch queries being routed in real-time\n",
        "- See which skills are selected\n",
        "- View dispatcher confidence scores\n",
        "- Track the complete workflow\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” **What You'll See**\n",
        "\n",
        "1. **ğŸ”¨ Query Received** - Your question enters the system\n",
        "2. **ğŸ§  Memory Loaded** - Previous context retrieved (if any)\n",
        "3. **ğŸ¤” Planner Analyzing** - Gemini decides which specialist\n",
        "4. **ğŸ”§ Tool Called** - Specialist's tool is invoked\n",
        "5. **ğŸ¯ Dispatcher Routing** - UAL analyzes query for best skill\n",
        "6. **âœ¨ Skill Selected** - LoRA skill chosen with confidence score\n",
        "7. **âš™ï¸ Processing** - Backend model uses the adapter\n",
        "8. **âœ… Response Ready** - Answer delivered to you\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  **Conversation Memory**\n",
        "\n",
        "The system remembers:\n",
        "- Previous questions and answers\n",
        "- Context from earlier in the conversation\n",
        "- Uses this to give better responses\n",
        "\n",
        "Click \"ğŸ—‘ï¸ Clear\" to reset memory and start fresh.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ­ **Behind the Scenes**\n",
        "\n",
        "**Tool Wrapping:**\n",
        "- Original tools are wrapped with logging\n",
        "- Every action is tracked and displayed\n",
        "- No functionality changed - just visibility added\n",
        "\n",
        "**Async Handling:**\n",
        "- Proper async/await for Gemini API\n",
        "- Session reuse for efficiency\n",
        "- Clean shutdown - no warnings\n",
        "\n",
        "---\n",
        "\n",
        "### â±ï¸ **Expected Time**\n",
        "**~10 seconds** to create interface\n",
        "\n",
        "### âœ… **Success Indicators**\n",
        "```\n",
        "âœ… Tool functions wrapped with activity logging\n",
        "âœ… Runner initialized with existing planner\n",
        "âœ… Gradio interface created!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸš€ **How to Launch**\n",
        "After running this cell, execute:\n",
        "```python\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "erw-G13Ov375"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "from google.genai import types as genai_types\n",
        "from typing import Dict, List, Tuple\n",
        "import json\n",
        "\n",
        "print('='*70)\n",
        "print('ğŸ”§ Setting up Gradio with Activity Logging')\n",
        "print('='*70)\n",
        "\n",
        "# Activity log storage\n",
        "activity_log = []\n",
        "\n",
        "# Conversation memory storage\n",
        "conversation_history: List[Tuple[str, str]] = []\n",
        "\n",
        "# Session management\n",
        "current_session = None\n",
        "runner = None\n",
        "\n",
        "\n",
        "def log_activity(timestamp, stage, agent, details):\n",
        "    \"\"\"Log activity for tracking panel\"\"\"\n",
        "    entry = {\n",
        "        'timestamp': timestamp,\n",
        "        'stage': stage,\n",
        "        'agent': agent,\n",
        "        'details': details\n",
        "    }\n",
        "    activity_log.append(entry)\n",
        "    return entry\n",
        "\n",
        "\n",
        "def format_activity_log():\n",
        "    \"\"\"Format activity log for display\"\"\"\n",
        "    if not activity_log:\n",
        "        return \"ğŸ”µ **Waiting for query...**\\n\\nActivity will be logged here.\"\n",
        "\n",
        "    output = \"\"\n",
        "    for i, entry in enumerate(activity_log, 1):\n",
        "        output += f\"**{i}. [{entry['timestamp']}] {entry['stage']}**\\n\"\n",
        "        output += f\"   Agent: {entry['agent']}\\n\"\n",
        "\n",
        "        if isinstance(entry['details'], dict):\n",
        "            for key, value in entry['details'].items():\n",
        "                output += f\"   â€¢ {key}: {value}\\n\"\n",
        "        else:\n",
        "            output += f\"   â€¢ {entry['details']}\\n\"\n",
        "\n",
        "        output += \"\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PATCH: Add Logging to Existing Tools\n",
        "# =============================================================================\n",
        "\n",
        "print('\\nğŸ”§ Patching existing tools with logging...\\n')\n",
        "\n",
        "# Import existing components\n",
        "try:\n",
        "    from __main__ import agents, planner, sales_agent, support_agent, account_agent, analyst_agent\n",
        "    from __main__ import sales_tool as original_sales_tool\n",
        "    from __main__ import support_tool as original_support_tool\n",
        "    from __main__ import account_tool as original_account_tool\n",
        "    from __main__ import analyst_tool as original_analyst_tool\n",
        "\n",
        "    components_available = True\n",
        "    print('âœ… Found existing agents and tools')\n",
        "except ImportError as e:\n",
        "    components_available = False\n",
        "    print(f'âŒ Could not import components: {e}')\n",
        "    print('   Make sure you ran the agent creation cell first!')\n",
        "\n",
        "\n",
        "def wrap_tool_with_logging(original_tool, agent_name, agent_key):\n",
        "    \"\"\"Wrap an existing tool function with logging\"\"\"\n",
        "    def logged_tool(query: str) -> Dict[str, str]:\n",
        "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "\n",
        "        # Log: Tool called\n",
        "        log_activity(timestamp, \"ğŸ”§ Tool Called\", agent_name,\n",
        "                     {\"action\": \"Processing query\",\n",
        "                      \"query\": query[:80] + (\"...\" if len(query) > 80 else \"\")})\n",
        "\n",
        "        # Log: Dispatcher analyzing\n",
        "        log_activity(timestamp, \"ğŸ¯ Dispatcher Routing\", agent_name,\n",
        "                     {\"status\": \"Analyzing query semantically...\"})\n",
        "\n",
        "        # Call the original tool (which runs the dispatcher)\n",
        "        result = original_tool(query)\n",
        "\n",
        "        # Log: Skill selected (extract from result)\n",
        "        log_activity(timestamp, \"âœ¨ Skill Selected\", agent_name,\n",
        "                     {\n",
        "                         \"skill\": result.get('skill_selected', 'unknown'),\n",
        "                         \"confidence\": result.get('confidence', 'N/A'),\n",
        "                         \"available_skills\": \", \".join(result.get('all_skills_available', []))\n",
        "                     })\n",
        "\n",
        "        # Log: Processing with skill\n",
        "        if result.get('skill_selected') and result.get('skill_selected') != 'base':\n",
        "            log_activity(timestamp, \"âš™ï¸ LoRA Adapter Loading\", agent_name,\n",
        "                         {\"action\": f\"Using '{result['skill_selected']}' LoRA adapter\",\n",
        "                          \"backend\": result.get('model', 'unknown')})\n",
        "        else:\n",
        "            log_activity(timestamp, \"âš ï¸ Base Model Used\", agent_name,\n",
        "                         {\"reason\": \"No skill selected (below threshold)\",\n",
        "                          \"note\": \"Check if confidence_threshold is 0.05 (not 0.30)\"})\n",
        "\n",
        "        return result\n",
        "\n",
        "    # Preserve function metadata\n",
        "    logged_tool.__name__ = original_tool.__name__\n",
        "    logged_tool.__doc__ = original_tool.__doc__\n",
        "\n",
        "    return logged_tool\n",
        "\n",
        "\n",
        "# Wrap the existing tools\n",
        "if components_available:\n",
        "    print('Creating logged versions of tools...')\n",
        "\n",
        "    logged_sales_tool = wrap_tool_with_logging(original_sales_tool, \"Sales Rep\", \"sales_rep\")\n",
        "    logged_support_tool = wrap_tool_with_logging(original_support_tool, \"Support Specialist\", \"support_specialist\")\n",
        "    logged_account_tool = wrap_tool_with_logging(original_account_tool, \"Account Manager\", \"account_manager\")\n",
        "    logged_analyst_tool = wrap_tool_with_logging(original_analyst_tool, \"Data Analyst\", \"data_analyst\")\n",
        "\n",
        "    print('âœ… Logged tool wrappers created')\n",
        "\n",
        "    # Patch the agents with logged tools\n",
        "    print('\\nPatching agents with logged tools...')\n",
        "    from google.adk.tools import FunctionTool\n",
        "\n",
        "    # Update each agent's tools\n",
        "    sales_agent._tools = [FunctionTool(logged_sales_tool)]\n",
        "    sales_agent.tools = sales_agent._tools\n",
        "    print('  âœ… Patched sales_agent')\n",
        "\n",
        "    support_agent._tools = [FunctionTool(logged_support_tool)]\n",
        "    support_agent.tools = support_agent._tools\n",
        "    print('  âœ… Patched support_agent')\n",
        "\n",
        "    account_agent._tools = [FunctionTool(logged_account_tool)]\n",
        "    account_agent.tools = account_agent._tools\n",
        "    print('  âœ… Patched account_agent')\n",
        "\n",
        "    analyst_agent._tools = [FunctionTool(logged_analyst_tool)]\n",
        "    analyst_agent.tools = analyst_agent._tools\n",
        "    print('  âœ… Patched analyst_agent')\n",
        "\n",
        "    # Update planner's sub-agents references\n",
        "    planner._sub_agents = [sales_agent, support_agent, account_agent, analyst_agent]\n",
        "    planner.sub_agents = planner._sub_agents\n",
        "    print('  âœ… Updated planner with patched agents')\n",
        "\n",
        "    print('\\nâœ… All agents now have logging!\\n')\n",
        "else:\n",
        "    print('\\nâŒ Cannot patch tools - components not available\\n')\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Initialize Runner\n",
        "# =============================================================================\n",
        "\n",
        "print('Initializing runner...')\n",
        "\n",
        "if components_available:\n",
        "    from google.adk.runners import InMemoryRunner\n",
        "    runner = InMemoryRunner(agent=planner, app_name=\"crm_ual_demo\")\n",
        "    print('âœ… Runner initialized with patched planner\\n')\n",
        "else:\n",
        "    runner = None\n",
        "    print('âŒ Cannot initialize runner\\n')\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Async Query Processing\n",
        "# =============================================================================\n",
        "\n",
        "async def initialize_session():\n",
        "    \"\"\"Initialize or reuse session for conversation memory\"\"\"\n",
        "    global current_session\n",
        "\n",
        "    if current_session is None and runner is not None:\n",
        "        current_session = await runner.session_service.create_session(\n",
        "            app_name=\"crm_ual_demo\",\n",
        "            user_id=\"demo_user\"\n",
        "        )\n",
        "        print(f'âœ… Session created: {current_session.id}')\n",
        "\n",
        "    return current_session\n",
        "\n",
        "\n",
        "async def process_query_async(query: str):\n",
        "    \"\"\"Process query with proper async cleanup and memory\"\"\"\n",
        "    global activity_log, conversation_history\n",
        "\n",
        "    activity_log = []  # Clear previous logs\n",
        "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "\n",
        "    # Log: Query received\n",
        "    log_activity(timestamp, \"ğŸ”¨ Query Received\", \"System\",\n",
        "                 {\"query\": query})\n",
        "\n",
        "    # Show conversation context if exists\n",
        "    if conversation_history:\n",
        "        log_activity(timestamp, \"ğŸ§  Memory Loaded\", \"System\",\n",
        "                     {\"context\": f\"{len(conversation_history)} previous exchanges\"})\n",
        "\n",
        "    # Log: Planner analyzing\n",
        "    log_activity(timestamp, \"ğŸ¤” Planner Analyzing\", \"CRM Planner (Gemini)\",\n",
        "                 {\"action\": \"Determining best specialist agent...\"})\n",
        "\n",
        "    if runner is None:\n",
        "        return \"âŒ Error: Runner not initialized. Make sure agents are created!\"\n",
        "\n",
        "    try:\n",
        "        # Initialize/get session (reuses for memory)\n",
        "        session = await initialize_session()\n",
        "\n",
        "        # Build context-aware query if there's conversation history\n",
        "        context_query = query\n",
        "        if conversation_history:\n",
        "            # Add recent context (last 3 exchanges)\n",
        "            recent = conversation_history[-3:]\n",
        "            context_prefix = \"Previous context:\\n\"\n",
        "            for i, (prev_q, prev_a) in enumerate(recent, 1):\n",
        "                context_prefix += f\"{i}. Q: {prev_q}\\n   A: {prev_a[:100]}\\n\"\n",
        "            context_prefix += f\"\\nCurrent query: {query}\"\n",
        "            context_query = context_prefix\n",
        "\n",
        "        # Run query\n",
        "        content = genai_types.Content(\n",
        "            parts=[genai_types.Part(text=context_query)]\n",
        "        )\n",
        "\n",
        "        response_text = \"\"\n",
        "        function_calls_made = []\n",
        "\n",
        "        async for event in runner.run_async(\n",
        "            user_id=session.user_id,\n",
        "            session_id=session.id,\n",
        "            new_message=content\n",
        "        ):\n",
        "            if event.content and event.content.parts:\n",
        "                for part in event.content.parts:\n",
        "                    # Handle text responses\n",
        "                    if part.text:\n",
        "                        response_text = part.text\n",
        "\n",
        "                    # Handle function calls\n",
        "                    if hasattr(part, 'function_call') and part.function_call:\n",
        "                        fc = part.function_call\n",
        "                        function_calls_made.append(fc.name)\n",
        "                        log_activity(\n",
        "                            datetime.now().strftime('%H:%M:%S'),\n",
        "                            \"ğŸ”„ ADK Function Call\",\n",
        "                            \"System\",\n",
        "                            {\"function\": fc.name,\n",
        "                             \"note\": \"Tool function being invoked...\"}\n",
        "                        )\n",
        "\n",
        "        # Log: Response ready\n",
        "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "\n",
        "        if not function_calls_made:\n",
        "            log_activity(timestamp, \"âš ï¸ No Tools Called\", \"System\",\n",
        "                         {\"warning\": \"Agent responded directly without calling tools!\",\n",
        "                          \"suggestion\": \"Check if instructions are forceful enough\"})\n",
        "\n",
        "        log_activity(timestamp, \"âœ… Response Ready\", \"System\",\n",
        "                     {\"status\": \"Query processed successfully\",\n",
        "                      \"tools_called\": len(function_calls_made)})\n",
        "\n",
        "        # Store in conversation memory\n",
        "        conversation_history.append((query, response_text))\n",
        "\n",
        "        return response_text\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_msg = f\"âŒ Error: {str(e)}\\n\\n{traceback.format_exc()}\"\n",
        "        log_activity(\n",
        "            datetime.now().strftime('%H:%M:%S'),\n",
        "            \"âŒ Error Occurred\",\n",
        "            \"System\",\n",
        "            {\"error\": str(e)}\n",
        "        )\n",
        "        return error_msg\n",
        "\n",
        "\n",
        "def process_query_sync(query: str, history):\n",
        "    \"\"\"Sync wrapper for Gradio\"\"\"\n",
        "    if not query.strip():\n",
        "        return history, format_activity_log()\n",
        "\n",
        "    try:\n",
        "        # Run async query\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "\n",
        "        loop = asyncio.get_event_loop()\n",
        "        response = loop.run_until_complete(process_query_async(query))\n",
        "\n",
        "        # Update history\n",
        "        history.append((query, response))\n",
        "\n",
        "        # Format activity log\n",
        "        activity_text = format_activity_log()\n",
        "\n",
        "        return history, activity_text\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_msg = f\"âŒ Error: {str(e)}\\n\\n{traceback.format_exc()}\"\n",
        "        history.append((query, error_msg))\n",
        "        return history, format_activity_log()\n",
        "\n",
        "\n",
        "def clear_conversation():\n",
        "    \"\"\"Clear conversation history and session\"\"\"\n",
        "    global conversation_history, current_session, activity_log\n",
        "    conversation_history = []\n",
        "    current_session = None\n",
        "    activity_log = []\n",
        "    return (\n",
        "        [],\n",
        "        \"ğŸ”µ **Cleared.**\\n\\n\"\n",
        "        \"Conversation memory reset. Send a new query to start.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Example queries\n",
        "EXAMPLE_QUERIES = [\n",
        "    \"MEDDPICC qualification for $1.2M enterprise opportunity\",\n",
        "    \"Customer asking about GDPR data subject rights and compliance\",\n",
        "    \"Build Salesforce flow for high-velocity deal approvals\",\n",
        "    \"RFM segmentation analysis for targeted marketing campaigns\",\n",
        "    \"Help me negotiate pricing using value-based approach\",\n",
        "    \"Multi-tenancy architecture with row-level security\",\n",
        "]\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Gradio Interface\n",
        "# =============================================================================\n",
        "\n",
        "print('ğŸ¨ Creating Gradio interface...\\n')\n",
        "\n",
        "with gr.Blocks(title=\"UAL Multi-Agent CRM System\", theme=\"soft\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸš€ UAL Adapter - Multi-Agent CRM System\n",
        "\n",
        "    **Dynamic LoRA Skill Loading Demonstration**\n",
        "\n",
        "    Watch how queries are routed to specialist agents,\n",
        "    and see which LoRA skills are selected in real-time!\n",
        "\n",
        "    **NEW:** Improved logging - shows actual skill selection!\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Left side - Chat Interface\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"ğŸ’¬ CRM Assistant\",\n",
        "                height=500,\n",
        "                show_label=True\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                query_box = gr.Textbox(\n",
        "                    placeholder=\"Ask about sales, support, analytics, or account management...\",\n",
        "                    label=\"Your Query\",\n",
        "                    lines=2,\n",
        "                    show_label=False\n",
        "                )\n",
        "\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\n",
        "                    \"ğŸš€ Submit\",\n",
        "                    variant=\"primary\",\n",
        "                    scale=2\n",
        "                )\n",
        "                clear_btn = gr.Button(\"ğŸ—‘ï¸ Clear\", scale=1)\n",
        "\n",
        "            gr.Markdown(\"### ğŸ’¡ Example Queries:\")\n",
        "            gr.Examples(\n",
        "                examples=EXAMPLE_QUERIES,\n",
        "                inputs=query_box,\n",
        "                label=\"Try these queries:\"\n",
        "            )\n",
        "\n",
        "        # Right side - Activity Tracking\n",
        "        with gr.Column(scale=2):\n",
        "            activity_panel = gr.Markdown(\n",
        "                value=\"ğŸ”µ **Waiting for query...**\\n\\nActivity will be logged here.\",\n",
        "                label=\"ğŸ“Š Activity Tracker\",\n",
        "                elem_id=\"activity_tracker\"\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            ---\n",
        "            ### ğŸ¯ What to Look For:\n",
        "\n",
        "            - **ğŸ”¨ Query Received**: Your query enters the system\n",
        "            - **ğŸ§  Memory Loaded**: Previous context retrieved\n",
        "            - **ğŸ¤” Planner Analyzing**: Gemini decides which specialist\n",
        "            - **ğŸ”„ ADK Function Call**: Tool is being invoked\n",
        "            - **ğŸ”§ Tool Called**: Sub-agent's tool function runs\n",
        "            - **ğŸ¯ Dispatcher Routing**: UAL dispatcher analyzes query\n",
        "            - **âœ¨ Skill Selected**: Best LoRA skill chosen w/ confidence\n",
        "            - **âš™ï¸ LoRA Adapter Loading**: Backend loads the skill\n",
        "            - **âš ï¸ Base Model Used**: No skill selected (threshold issue)\n",
        "            - **âœ… Response Ready**: Final answer prepared\n",
        "            - **âš ï¸ No Tools Called**: Agent didn't use tools (instruction issue)\n",
        "\n",
        "            ---\n",
        "\n",
        "            ### ğŸ—ï¸ Architecture:\n",
        "\n",
        "            ```\n",
        "            Planner (Gemini Flash)\n",
        "              â”œâ”€ Sales Rep (Qwen 0.5B)\n",
        "              â”œâ”€ Support (TinyLlama 1.1B)\n",
        "              â”œâ”€ Account Mgr (SmolLM 360M)\n",
        "              â””â”€ Data Analyst (Qwen 1.5B)\n",
        "            ```\n",
        "\n",
        "            Each agent has a **UAL Dispatcher** that selects skills!\n",
        "\n",
        "            ---\n",
        "\n",
        "            ### ğŸ” Debugging:\n",
        "\n",
        "            **If you see \"No Tools Called\":**\n",
        "            - Instructions may not be forceful enough\n",
        "            - Agent responding without tools\n",
        "\n",
        "            **If you see \"Base Model Used\":**\n",
        "            - Threshold too high (should be 0.05, not 0.30)\n",
        "            - Check confidence scores in logs\n",
        "\n",
        "            **If skills not showing:**\n",
        "            - Confidence threshold needs lowering\n",
        "            - Check dispatcher configuration\n",
        "\n",
        "            ---\n",
        "\n",
        "            ### ğŸ§  Memory:\n",
        "            Sessions are reused for conversation context.\n",
        "            Click \"Clear\" to reset memory.\n",
        "            \"\"\")\n",
        "\n",
        "    # Event handlers\n",
        "    submit_btn.click(\n",
        "        fn=process_query_sync,\n",
        "        inputs=[query_box, chatbot],\n",
        "        outputs=[chatbot, activity_panel]\n",
        "    ).then(\n",
        "        fn=lambda: \"\",\n",
        "        outputs=query_box\n",
        "    )\n",
        "\n",
        "    query_box.submit(\n",
        "        fn=process_query_sync,\n",
        "        inputs=[query_box, chatbot],\n",
        "        outputs=[chatbot, activity_panel]\n",
        "    ).then(\n",
        "        fn=lambda: \"\",\n",
        "        outputs=query_box\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_conversation,\n",
        "        outputs=[chatbot, activity_panel]\n",
        "    )\n",
        "\n",
        "print('âœ… Gradio interface created!\\n')\n",
        "print('='*70)\n",
        "print('ğŸ‰ SETUP COMPLETE!')\n",
        "print('='*70)\n",
        "print('\\nâœ… What was done:')\n",
        "print('   â€¢ Imported existing agents and tools')\n",
        "print('   â€¢ Wrapped tools with logging (no recreation)')\n",
        "print('   â€¢ Patched agents to use logged tools')\n",
        "print('   â€¢ Runner initialized with patched planner')\n",
        "print('   â€¢ Gradio interface ready')\n",
        "print('\\nğŸš€ To launch, run:')\n",
        "print('   demo.launch(share=True, debug=True)')\n",
        "print('\\nğŸ“Š Your logs will now show:')\n",
        "print('   ğŸ”§ Tool Called')\n",
        "print('   ğŸ¯ Dispatcher Routing')\n",
        "print('   âœ¨ Skill Selected (negotiation, communication, etc.)')\n",
        "print('   âš™ï¸ LoRA Adapter Loading')\n",
        "print('\\nâš ï¸  IMPORTANT REMINDERS:')\n",
        "print('   1. Make sure confidence_threshold=0.05 (not 0.30) in dispatchers')\n",
        "print('   2. Make sure \"config\" key exists in agents dictionary')\n",
        "print('   3. Run agent creation cell BEFORE this cell')\n",
        "print('='*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibkHLiaYKuM7",
        "outputId": "60a4eb94-0fbf-4de5-f4ab-859307d36806"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ğŸ”§ Setting up Gradio with Activity Logging\n",
            "======================================================================\n",
            "\n",
            "ğŸ”§ Patching existing tools with logging...\n",
            "\n",
            "âœ… Found existing agents and tools\n",
            "Creating logged versions of tools...\n",
            "âœ… Logged tool wrappers created\n",
            "\n",
            "Patching agents with logged tools...\n",
            "  âœ… Patched sales_agent\n",
            "  âœ… Patched support_agent\n",
            "  âœ… Patched account_agent\n",
            "  âœ… Patched analyst_agent\n",
            "  âœ… Updated planner with patched agents\n",
            "\n",
            "âœ… All agents now have logging!\n",
            "\n",
            "Initializing runner...\n",
            "âœ… Runner initialized with patched planner\n",
            "\n",
            "ğŸ¨ Creating Gradio interface...\n",
            "\n",
            "âœ… Gradio interface created!\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ SETUP COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "âœ… What was done:\n",
            "   â€¢ Imported existing agents and tools\n",
            "   â€¢ Wrapped tools with logging (no recreation)\n",
            "   â€¢ Patched agents to use logged tools\n",
            "   â€¢ Runner initialized with patched planner\n",
            "   â€¢ Gradio interface ready\n",
            "\n",
            "ğŸš€ To launch, run:\n",
            "   demo.launch(share=True, debug=True)\n",
            "\n",
            "ğŸ“Š Your logs will now show:\n",
            "   ğŸ”§ Tool Called\n",
            "   ğŸ¯ Dispatcher Routing\n",
            "   âœ¨ Skill Selected (negotiation, communication, etc.)\n",
            "   âš™ï¸ LoRA Adapter Loading\n",
            "\n",
            "âš ï¸  IMPORTANT REMINDERS:\n",
            "   1. Make sure confidence_threshold=0.05 (not 0.30) in dispatchers\n",
            "   2. Make sure \"config\" key exists in agents dictionary\n",
            "   3. Run agent creation cell BEFORE this cell\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yzzWIZwvhvJW",
        "outputId": "1c76b05d-06e3-4b4a-fcf4-4d029a37e61e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c72edba1d363337f33.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c72edba1d363337f33.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Session created: 82b93ab3-c64c-4054-af49-29905aad86c1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-350' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/google/genai/client.py:90> exception=RuntimeError(\"Task <Task pending name='Task-350' coro=<AsyncClient.aclose() running at /usr/local/lib/python3.12/dist-packages/google/genai/client.py:115>> got Future <Task pending name='Task-352' coro=<_wait_for_close() running at /usr/local/lib/python3.12/dist-packages/aiohttp/connector.py:136>> attached to a different loop\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/client.py\", line 115, in aclose\n",
            "    await self._api_client.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1800, in aclose\n",
            "    await self._aiohttp_session.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/aiohttp/client.py\", line 1356, in close\n",
            "    await self._connector.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/aiohttp/connector.py\", line 1044, in close\n",
            "    await super().close(abort_ssl=abort_ssl or self._ssl_shutdown_timeout == 0)\n",
            "  File \"/usr/lib/python3.12/asyncio/futures.py\", line 289, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "RuntimeError: Task <Task pending name='Task-350' coro=<AsyncClient.aclose() running at /usr/local/lib/python3.12/dist-packages/google/genai/client.py:115>> got Future <Task pending name='Task-352' coro=<_wait_for_close() running at /usr/local/lib/python3.12/dist-packages/aiohttp/connector.py:136>> attached to a different loop\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "ERROR:asyncio:Unclosed connector\n",
            "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7e5bfb0cb410>, 19398.94939438)])']\n",
            "connector: <aiohttp.connector.TCPConnector object at 0x7e5bfb253b30>\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-379' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/google/genai/client.py:90> exception=RuntimeError(\"Task <Task pending name='Task-379' coro=<AsyncClient.aclose() running at /usr/local/lib/python3.12/dist-packages/google/genai/client.py:115>> got Future <Task pending name='Task-382' coro=<_wait_for_close() running at /usr/local/lib/python3.12/dist-packages/aiohttp/connector.py:136>> attached to a different loop\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/client.py\", line 115, in aclose\n",
            "    await self._api_client.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1800, in aclose\n",
            "    await self._aiohttp_session.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/aiohttp/client.py\", line 1356, in close\n",
            "    await self._connector.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/aiohttp/connector.py\", line 1044, in close\n",
            "    await super().close(abort_ssl=abort_ssl or self._ssl_shutdown_timeout == 0)\n",
            "  File \"/usr/lib/python3.12/asyncio/futures.py\", line 289, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "RuntimeError: Task <Task pending name='Task-379' coro=<AsyncClient.aclose() running at /usr/local/lib/python3.12/dist-packages/google/genai/client.py:115>> got Future <Task pending name='Task-382' coro=<_wait_for_close() running at /usr/local/lib/python3.12/dist-packages/aiohttp/connector.py:136>> attached to a different loop\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://c72edba1d363337f33.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pC6JRUPNaWVc"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.8.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9465a9e5ddaa4b3fb751efdedc93117d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1df1f90b3ca549928d07a7dad2b86e16",
              "IPY_MODEL_075aca08b2d440a68915062cc52ead1a",
              "IPY_MODEL_4a456d5565d24bc9b471a24247e39039"
            ],
            "layout": "IPY_MODEL_760c37e2fe3941bab2a874b0ba1f74f6"
          }
        },
        "1df1f90b3ca549928d07a7dad2b86e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a8677b4c4b462c8f35fb85aa5d821d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b3ebba95ea854a5ca86686eb83a0cb3b",
            "value": "Batches:â€‡100%"
          }
        },
        "075aca08b2d440a68915062cc52ead1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb66f5534184146b516f782639d997d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5fe6aa11475452eb09aaf1d7f231284",
            "value": 1
          }
        },
        "4a456d5565d24bc9b471a24247e39039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3551f6a63c840d3ba7876efe3c0bc14",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b3ec243827a46c0acfdc56d19bf3860",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡â€‡3.59it/s]"
          }
        },
        "760c37e2fe3941bab2a874b0ba1f74f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6a8677b4c4b462c8f35fb85aa5d821d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ebba95ea854a5ca86686eb83a0cb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb66f5534184146b516f782639d997d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fe6aa11475452eb09aaf1d7f231284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3551f6a63c840d3ba7876efe3c0bc14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3ec243827a46c0acfdc56d19bf3860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab3584101de46138c2d32dc74691de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_732e8fee776e412f82fefc18dfda5738",
              "IPY_MODEL_5fd52edae91149b2a2fdd4ae1d7e2dc8",
              "IPY_MODEL_32b211c2c62e44b298d8acf3e73f2103"
            ],
            "layout": "IPY_MODEL_264fd1076c9240edb29ada3aa3ee648d"
          }
        },
        "732e8fee776e412f82fefc18dfda5738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c0545bd5228497ba4cbc090edf3c032",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_28e6a84ec2f84b4585333faeb15410d0",
            "value": "Batches:â€‡100%"
          }
        },
        "5fd52edae91149b2a2fdd4ae1d7e2dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f631c4351e4d83851e461e5fd27e1b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c64ba719c70844b6aa7b7a466b3cde8a",
            "value": 1
          }
        },
        "32b211c2c62e44b298d8acf3e73f2103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d127a33e547c421689b935a186678282",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f3fdccf85758472989fdb77711a3083a",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡52.14it/s]"
          }
        },
        "264fd1076c9240edb29ada3aa3ee648d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0545bd5228497ba4cbc090edf3c032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e6a84ec2f84b4585333faeb15410d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f631c4351e4d83851e461e5fd27e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c64ba719c70844b6aa7b7a466b3cde8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d127a33e547c421689b935a186678282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fdccf85758472989fdb77711a3083a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c36d0a05f1944155b0b26f01079fe4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95da796ec2f04398ba85acf0bb549953",
              "IPY_MODEL_7d1883b8cea64ec5ac0b6009d4348f2e",
              "IPY_MODEL_17fca6fc1bb343d697923a748027334c"
            ],
            "layout": "IPY_MODEL_2f79615a0ea24bce9f99fd7b47d8d60e"
          }
        },
        "95da796ec2f04398ba85acf0bb549953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32e4fb1431349cd911a000fa07c3a0f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_019698f3535b4e69bf7550919919f047",
            "value": "Batches:â€‡100%"
          }
        },
        "7d1883b8cea64ec5ac0b6009d4348f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6669128ad00540afa7c31822687e6e74",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e776195ebdee427898db105e1cacb78f",
            "value": 1
          }
        },
        "17fca6fc1bb343d697923a748027334c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ee79c4994248069e14d4069b61eaff",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ec93a8b903784bc9ab3174aae4a7f6a7",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡42.26it/s]"
          }
        },
        "2f79615a0ea24bce9f99fd7b47d8d60e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32e4fb1431349cd911a000fa07c3a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019698f3535b4e69bf7550919919f047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6669128ad00540afa7c31822687e6e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e776195ebdee427898db105e1cacb78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3ee79c4994248069e14d4069b61eaff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec93a8b903784bc9ab3174aae4a7f6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711168eadc0d454989fa3929d75e7b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52ca316900c648129ff2aa44020eff71",
              "IPY_MODEL_c41e8244462d4882990e37eef5e5e2b7",
              "IPY_MODEL_4f41383c47cd494b847bc0bcda831c76"
            ],
            "layout": "IPY_MODEL_8b52b86208114a27b12984dd600665b2"
          }
        },
        "52ca316900c648129ff2aa44020eff71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef789fb211ee44b09fc7d02607e7acba",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b976fcd40b84431f8bbb360168001707",
            "value": "Batches:â€‡100%"
          }
        },
        "c41e8244462d4882990e37eef5e5e2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3414cdb719e14617914babc8283fa2b1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_871c69ab0a47497481f0f6b4c5f1e51b",
            "value": 1
          }
        },
        "4f41383c47cd494b847bc0bcda831c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f9a02324adf4860938bb4ae4279c026",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b51dab3d2e0c4f4b81272a8cef4d08a8",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡40.98it/s]"
          }
        },
        "8b52b86208114a27b12984dd600665b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef789fb211ee44b09fc7d02607e7acba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b976fcd40b84431f8bbb360168001707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3414cdb719e14617914babc8283fa2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871c69ab0a47497481f0f6b4c5f1e51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f9a02324adf4860938bb4ae4279c026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51dab3d2e0c4f4b81272a8cef4d08a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24a7714523984fecb0f00588222ef10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_136a1488197b4414819d638364aad7e7",
              "IPY_MODEL_7793ac75620e444299ab766be23a387c",
              "IPY_MODEL_d950d691a23f47269be39e142822d1df"
            ],
            "layout": "IPY_MODEL_ea02688fe2044a288e50bd7da1099e45"
          }
        },
        "136a1488197b4414819d638364aad7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b1845c26f847d8bbf00099eed85d10",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_582b00fc6ad24989892ee45725397e33",
            "value": "Batches:â€‡100%"
          }
        },
        "7793ac75620e444299ab766be23a387c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b551fe2978d94c0a8610ee0be64061ee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f01c13ac88cc4d2aae1255e43089bb0e",
            "value": 1
          }
        },
        "d950d691a23f47269be39e142822d1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79eba3f766a7412280aaa5a63fc6074a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7637027db71d441893d1a013c9f27595",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡48.90it/s]"
          }
        },
        "ea02688fe2044a288e50bd7da1099e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b1845c26f847d8bbf00099eed85d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582b00fc6ad24989892ee45725397e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b551fe2978d94c0a8610ee0be64061ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f01c13ac88cc4d2aae1255e43089bb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79eba3f766a7412280aaa5a63fc6074a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7637027db71d441893d1a013c9f27595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0fbb9b594024f2899d4d38809b7b7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49f14d60103b4d92b3717e714b98d596",
              "IPY_MODEL_6c39c39b339c492f86a0b408c296ab7f",
              "IPY_MODEL_f2129644277d4cbba52e1cc7a83401a0"
            ],
            "layout": "IPY_MODEL_2b6ad276be7b4b49bba679bcc8531831"
          }
        },
        "49f14d60103b4d92b3717e714b98d596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6aae1151bf14bf980e7e9c211115130",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8462eabaf3c2462cb90df2981fef9630",
            "value": "Batches:â€‡100%"
          }
        },
        "6c39c39b339c492f86a0b408c296ab7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baed451eeb804bfa981a0b6487123650",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0552cb106b9463db289cdaa29395ea4",
            "value": 1
          }
        },
        "f2129644277d4cbba52e1cc7a83401a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f98aedeb73425c9d8f7f2c2ddc5631",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_60f3f0bbc73c47b9bf7b8d130af0e459",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡40.48it/s]"
          }
        },
        "2b6ad276be7b4b49bba679bcc8531831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6aae1151bf14bf980e7e9c211115130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8462eabaf3c2462cb90df2981fef9630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baed451eeb804bfa981a0b6487123650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0552cb106b9463db289cdaa29395ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92f98aedeb73425c9d8f7f2c2ddc5631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f3f0bbc73c47b9bf7b8d130af0e459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5d6a3ecffb432d92530bd73f99edb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aed64d37cff2444eb26deb97e2c50ca6",
              "IPY_MODEL_d4f8d78e52854cc2bc1057bca2ff097c",
              "IPY_MODEL_5e0f8d3b64ca4bd48c80f193c4e6bbe7"
            ],
            "layout": "IPY_MODEL_c30766d3199442d5b059cc4b076a1a52"
          }
        },
        "aed64d37cff2444eb26deb97e2c50ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e91a256e2fe4aafa844158e0a5cdcb7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_99cc3eb31c8e4b65bf7cb4235caa6027",
            "value": "Batches:â€‡100%"
          }
        },
        "d4f8d78e52854cc2bc1057bca2ff097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6806dd14628045bb8b31f82cc9b6e20c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2c9ec43929248ee86808394866a6882",
            "value": 1
          }
        },
        "5e0f8d3b64ca4bd48c80f193c4e6bbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c14aacf4a8041d398a5de792f3da991",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e0466d7b846d40349605628ff2a51824",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡52.17it/s]"
          }
        },
        "c30766d3199442d5b059cc4b076a1a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e91a256e2fe4aafa844158e0a5cdcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cc3eb31c8e4b65bf7cb4235caa6027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6806dd14628045bb8b31f82cc9b6e20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c9ec43929248ee86808394866a6882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c14aacf4a8041d398a5de792f3da991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0466d7b846d40349605628ff2a51824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffce7a32cd534598b13579297172c69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d83763a5a7b4759939d436fec9e43a4",
              "IPY_MODEL_f0586ed92beb4970a05ff90ecdec32bd",
              "IPY_MODEL_765f90aec0224991b5a03581c4aff5ea"
            ],
            "layout": "IPY_MODEL_59235e25bc0f4d3ba444b7a9488fad61"
          }
        },
        "9d83763a5a7b4759939d436fec9e43a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286df3016b65495a8a86b12904fe7c91",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_511d0f3e4c614768a3e25d70a9599af5",
            "value": "Batches:â€‡100%"
          }
        },
        "f0586ed92beb4970a05ff90ecdec32bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda9fd72761340daaa8be9134bad76cf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a277bbd8eda42e1a4cd781ac2742fa3",
            "value": 1
          }
        },
        "765f90aec0224991b5a03581c4aff5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af31c4416ac244fea34d20e283513956",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e7ba838ab7cc41e6a6be17cfeb873cb0",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡58.68it/s]"
          }
        },
        "59235e25bc0f4d3ba444b7a9488fad61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286df3016b65495a8a86b12904fe7c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511d0f3e4c614768a3e25d70a9599af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eda9fd72761340daaa8be9134bad76cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a277bbd8eda42e1a4cd781ac2742fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af31c4416ac244fea34d20e283513956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ba838ab7cc41e6a6be17cfeb873cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f112e4472648a39b2324bf6e5059fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fba7f0395144a0d8e3abba3a9f6e00f",
              "IPY_MODEL_87b34d0caf904fc893d13379fe8fdb55",
              "IPY_MODEL_580173caae6f4a619240d657737233d6"
            ],
            "layout": "IPY_MODEL_61af7612809f47b58d5b10c88bf34304"
          }
        },
        "1fba7f0395144a0d8e3abba3a9f6e00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786cb13089c640e4806ee708066504bb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fe8c2408f4e6493fbc65ef258fe8b555",
            "value": "Batches:â€‡100%"
          }
        },
        "87b34d0caf904fc893d13379fe8fdb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc36a91dd3c45e1ba261638b65a0f96",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22f629dde72e461c9bb8297f31a9d8d0",
            "value": 1
          }
        },
        "580173caae6f4a619240d657737233d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a80df9c96ae4a4381a71ffa54959ea6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_28c3dd0944d547f1a7f6c6b8e7c81e87",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡43.79it/s]"
          }
        },
        "61af7612809f47b58d5b10c88bf34304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786cb13089c640e4806ee708066504bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe8c2408f4e6493fbc65ef258fe8b555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc36a91dd3c45e1ba261638b65a0f96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f629dde72e461c9bb8297f31a9d8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a80df9c96ae4a4381a71ffa54959ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c3dd0944d547f1a7f6c6b8e7c81e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e806e0607bf45d4a17b2f145e12b748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_867990cb845846ee9c9a35e1ba5c649e",
              "IPY_MODEL_a6f0bf8b9ba446c7b238b547bfd0dc9d",
              "IPY_MODEL_d9181ea271a5402bae6e985b45c8877b"
            ],
            "layout": "IPY_MODEL_f3f349a18dc940dbb7cbd52369341bd5"
          }
        },
        "867990cb845846ee9c9a35e1ba5c649e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6111ba6004f44b899c12a670644dc77",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a4b50800f07b4377b7ef2688c60b3f9a",
            "value": "Batches:â€‡100%"
          }
        },
        "a6f0bf8b9ba446c7b238b547bfd0dc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731e2a9cbc2649ce89f7d8cdc8cbdfb0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0c9f3dbb10e4988ad4a493b4ebf0cd1",
            "value": 1
          }
        },
        "d9181ea271a5402bae6e985b45c8877b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_679863fcc37e4782b2075e1de00a825d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_764fdb2534b645da9a486cb486e0bc92",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡54.20it/s]"
          }
        },
        "f3f349a18dc940dbb7cbd52369341bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6111ba6004f44b899c12a670644dc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b50800f07b4377b7ef2688c60b3f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "731e2a9cbc2649ce89f7d8cdc8cbdfb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c9f3dbb10e4988ad4a493b4ebf0cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "679863fcc37e4782b2075e1de00a825d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "764fdb2534b645da9a486cb486e0bc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e221e6d03249e8bca58647f18b187c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62e63a3a7b074f5595a2c1629e3a078f",
              "IPY_MODEL_74c9616636004a8880318b07347d8b40",
              "IPY_MODEL_2032a01b762d4276ba96eaeda905ddb4"
            ],
            "layout": "IPY_MODEL_65df71d5917c46bb84ea27fab0be08cc"
          }
        },
        "62e63a3a7b074f5595a2c1629e3a078f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a7139506eaf45d4a97640db205bc159",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_66118c021b8a4458b38588f7f0be5fce",
            "value": "Batches:â€‡100%"
          }
        },
        "74c9616636004a8880318b07347d8b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ded6c729c4c84f34a168b48dccfe0f03",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b499faaef9984a418ba86fec2692ebea",
            "value": 1
          }
        },
        "2032a01b762d4276ba96eaeda905ddb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e853f996bc8a42e78eff493eb736f7c4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_90c6460d63804da9b9d2831a6426424a",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡53.31it/s]"
          }
        },
        "65df71d5917c46bb84ea27fab0be08cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a7139506eaf45d4a97640db205bc159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66118c021b8a4458b38588f7f0be5fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ded6c729c4c84f34a168b48dccfe0f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b499faaef9984a418ba86fec2692ebea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e853f996bc8a42e78eff493eb736f7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c6460d63804da9b9d2831a6426424a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef6498679236472e807ff4bcc56214e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6897f4e661ab43f3a046ee5b6b2e2641",
              "IPY_MODEL_412ca3359f4b4fc2bcb612d44f4d7e25",
              "IPY_MODEL_f45313470ca6497c92c9eeb004c83ec5"
            ],
            "layout": "IPY_MODEL_6cfd1df101014a5e9dbe5d99806f5906"
          }
        },
        "6897f4e661ab43f3a046ee5b6b2e2641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08970cdf1f374b9289deee606cca0fac",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9b920ddfb6524ae59c7f35679acc829a",
            "value": "Batches:â€‡100%"
          }
        },
        "412ca3359f4b4fc2bcb612d44f4d7e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60938fda0d3c4c49a454ffae9dd0712d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d17adfca6bb4429eb98b054eaa26884e",
            "value": 1
          }
        },
        "f45313470ca6497c92c9eeb004c83ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abfff29619dd43a29001669186aa0f11",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_795285a7956541be9deaed4a5f16f709",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡45.12it/s]"
          }
        },
        "6cfd1df101014a5e9dbe5d99806f5906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08970cdf1f374b9289deee606cca0fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b920ddfb6524ae59c7f35679acc829a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60938fda0d3c4c49a454ffae9dd0712d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17adfca6bb4429eb98b054eaa26884e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abfff29619dd43a29001669186aa0f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "795285a7956541be9deaed4a5f16f709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}